<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>1ミリもわからん</title><link>https://raahii.github.io/</link><description>Recent content on 1ミリもわからん</description><generator>Hugo -- gohugo.io</generator><language>ja-JP</language><lastBuildDate>Wed, 16 Oct 2019 21:58:50 +0900</lastBuildDate><atom:link href="https://raahii.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Ubuntu16.04でnvidiaドライバが再起動の度に無効になる</title><link>https://raahii.github.io/2019/10/16/nvidia-driver-not-work-after-reboot-on-ubuntu/</link><pubDate>Wed, 16 Oct 2019 21:58:50 +0900</pubDate><guid>https://raahii.github.io/2019/10/16/nvidia-driver-not-work-after-reboot-on-ubuntu/</guid><description>症状 Cudaのインストール手順を一通り済ませているにも関わらず，Ubuntuを起動するたびに nvidia-smi コマンドが実行できない．下記のようなエラーが吐かれる．
❯ nvidia-smi NVIDIA-SMI has failed because it couldn&amp;#39;t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running. 解決策 原因は .run ファイルを使ってドライバのインストールをしていたからだった．下記のページが参考になった．
Nvidia driver not work after reboot on Ubuntu - NVIDIA Developer Forums とはいえ，Ubuntuの場合はパッケージマネージャからドライバを直接インストールできるので，aptを使ったほうが良いと思う．まずはppaを追加する．
❯ sudo add-apt-repository ppa:graphics-drivers/ppa ❯ sudo apt update 肝心のドライバのパッケージだが，検索すると色々出てくるのでインストールされているGPU及びCUDAに合ったバージョンを入れる．NvidiaのHPから検索ができる．
❯ sudo apt search &amp;#34;nvidia-[0-9]+\$&amp;#34; Sorting... Done Full Text Search... Done nvidia-304/xenial 304.137-0ubuntu0~gpu16.04.1 amd64 NVIDIA legacy binary driver - version 304.</description></item><item><title>なぜioutil.ReadFileはioutil.ReadAllより速いか</title><link>https://raahii.github.io/2019/10/13/read-file-faster-golang/</link><pubDate>Sun, 13 Oct 2019 00:36:12 +0900</pubDate><guid>https://raahii.github.io/2019/10/13/read-file-faster-golang/</guid><description>TL;DR Goでファイル内容を読む場合 には，ioutil.ReadFile の方が ioutil.ReadAll よりも高速．なぜなら，読み込むデータの大きさがあらかじめわかっている場合は，内部のバッファサイズを決定でき，無駄なメモリ確保を無くせるから．
（いやなんでReadAllを使うんだよ，というのはさておき．）
ioutilパッケージの関数たち Go言語には入力や出力を抽象化したインターフェース（io.Reader やio.Writer など）がある．このインターフェースはいわゆるファイル的な振る舞いをするものをまるっと同じように扱うためにとても便利なもの．ioutil パッケージも当然，それらをベースとしてさまざまな関数を実装している．
io.Reader / io.Writer ただし，抽象化するということは，それぞれに特化できないということでもある．実際に ioutil.ReadAll のコードを読むと，最初に512 バイトのバッファを用意し，ファイルのEOFを検知するまで2倍，4倍，8倍…とそのサイズを大きくしながら読み込みを行っている．これは，io.Reader から一体どのくらいのデータを読み込むかわからないために行うバッファリングの処理である．
func ReadAll - ioutil そこで，ioutil.ReadFile関数では，事前にosパッケージを使ってファイルの大きさを取得し，バッファサイズをそのとおりに確保することで一度にすべての内容を読み込んでいる．ioutil.ReadAll と同じAPIを使いたい場合には，ファイルオープンしてサイズを取得したあとに，io.ReadFull やio.ReadAtLeastを使うと良いと思う．
ベンチマーク ソースコード
最初の関数は固定長のバッファで読み込んだ場合．次は ioutil.ReadAll を使う場合．これは指数的にバッファサイズを大きくしていくので可変長のバッファで読み込むということ．次に iotuil.ReadFile．最後がioutil.ReadFileと同等の処理をファイルサイズ取得+io.ReadAllで実装したもの．
package main import ( &amp;#34;io&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;os&amp;#34; &amp;#34;testing&amp;#34; ) var filename = &amp;#34;bigfile&amp;#34; // 804,335,663 bytes func BenchmarkFixedSizeBuffer(b *testing.B) { BUFSIZE := 4 * 1024 for i := 0; i &amp;lt; b.</description></item><item><title>HugoのビルドをGithub Actionで自動化する</title><link>https://raahii.github.io/2019/10/12/automating-hugo-builds-with-github-actions/</link><pubDate>Sat, 12 Oct 2019 18:20:16 +0900</pubDate><guid>https://raahii.github.io/2019/10/12/automating-hugo-builds-with-github-actions/</guid><description>台風が来て家に籠もるしかなくなったので，ブログのデザインをかえつつ，HugoのビルドをGithub Actionsで自動化した．公開にはGithub Pagesを使っている．
基本的に
GitHub Actions による GitHub Pages への自動デプロイ
のとおりにWorkflowを作ればできます．記事書いてくださった方自身が次のようなモジュールを公開されてるので神．
peaceiris/actions-gh-pages peaceiris/actions-hugo あえて注意点を上げるとすると，公開に &amp;lt;username&amp;gt;.github.io の直下？を使っている場合．このURLを使うには，名前を &amp;lt;username&amp;gt;.github.io としたリポジトリでGithub Pagesを設定する必要があるが，公開するソースはmaster ブランチのルートでなければならない（本来であれば他のブランチや特定のディレクトリを指定できる）．よって先の記事のような gh-pages ブランチにプッシュするやり方では実現できない．
そこで今回は，そもそも source ブランチをデフォルトブランチとすることにして，workflowでビルドしたものを master にプッシュするように変更した．
raahii.github.io/gh-pages.yml - GitHub 最近，研究に使ってるリポジトリにもGithub Actionsを設定したが，Dockerfileを使えば大体のことはできるし，直感的で使いやすい印象．ただドキュメントはあまり充実してないので複雑なことはできないかもしれない（以前もDockerfileのbuildのキャッシングがまだできないようだった）．今後も積極的に使っていこうと思う．
最後に，これは余談ですが，今回採用したLithiumというテーマにコードブロックのデザインが無かったので足してみました．Hugoのバージョン0.28以降にはChromaというGo製のシンタックスハイライターがついていて，設定ファイルに書き足すだけで色付けできるので便利ですね（今回はそもそも コードブロックの要素自体にcssが当たってなかったので外枠のデザインは作りました）．Hugoも相変わらずとっても良きです．
Syntax Highlighting | Hugo</description></item><item><title>画像データをサーバーにPOSTする</title><link>https://raahii.github.io/2019/08/04/files-upload/</link><pubDate>Sun, 04 Aug 2019 04:13:59 +0900</pubDate><guid>https://raahii.github.io/2019/08/04/files-upload/</guid><description>機械学習を使ったサービス/アプリを開発しているとクライアントから画像をサーバーに送って推論して結果を返す，ということをよくやるのでメモ．
1枚しか送らない場合 今の所自分はこのパターンが多いです．いくつか実現方法はあると思いますが，リクエストボディに直接画像データのバイナリを入れて送る方法がシンプルで好きです．クライアント側のコードはこんな感じ．
import json import urllib.parse import urllib.request # read image data f = open(&amp;#34;example.jpg&amp;#34;, &amp;#34;rb&amp;#34;) reqbody = f.read() f.close() # create request with urllib url = &amp;#34;http://localhost:5000&amp;#34; req = urllib.request.Request( url, reqbody, method=&amp;#34;POST&amp;#34;, headers={&amp;#34;Content-Type&amp;#34;: &amp;#34;application/octet-stream&amp;#34;}, ) # send the request and print response with urllib.request.urlopen(req) as res: print(json.loads(res.read())) 注意点として Content-Type に application/octet-stream を指定すると良いです．このMIMEタイプは曖昧なバイナリデータを指しており，ファイル種別を特に指定しないことを意味します（ref: MIME type: application/octet-stream ）．
urllibの場合，これを指定しないとPOSTのデフォルトのMIMEタイプである application/x-www-form-urlencoded となり，サーバー側で正しく受け取れないので気をつけてください．
一方でサーバー側（flaskの場合）のコードはこのようになります．画像データをOpenCVで読んで画像のshapeをjsonで返しています．
@app.route(&amp;#34;/&amp;#34;, methods=[&amp;#34;POST&amp;#34;]) def example(): # read request body as byte array _bytes = np.</description></item><item><title>Goで順列（permutation）を実装する</title><link>https://raahii.github.io/2019/04/07/permutations-in-go/</link><pubDate>Sun, 07 Apr 2019 12:22:55 +0900</pubDate><guid>https://raahii.github.io/2019/04/07/permutations-in-go/</guid><description>配列の並び替えのパターンの列挙をする関数をgolangで書く．ABC123で必要になったので．
TL;DR QuickPermを使うと良さそうです．
上記はコピペ用でこっからはいくつか方法を試して最後に速度比較します．
方法1: naive dfs 素直にdfsをする．前から数字を決めていって，決めたらその数字を選択肢から消して次へ行く．全部使ったら（選択肢が無くなったら）1つのパターンとして採択する．
上のコードで使ってるサブ関数たちです．この後の方法でも使ってるのですが面倒なので1度だけ掲載．
方法2: Heap Algorithm Heapのアルゴリズム を使う．
方法3: QuickPerm QuickPermを使う．
方法4（おまけ）: QuickPerm + Channel Generate all permutations in goとかを見ているとChannelを使った実装をしているので早いのか？と思って試してみた．
速度比較 go testでベンチマーク取ります．
方法3のQuickPermが一番早そうです．方法4は非同期でやっても単に結果くるまでブロッキングしてるので，goroutineやchannelの生成の分で普通に遅そうですね．まだgoroutineを書くの慣れてないのでコードが怪しいかもしれません．
goos: darwin goarch: amd64 pkg: github.com/raahii/go-sandbox/permutations BenchmarkPermute1-4 2 684403978 ns/op 637542560 B/op 9895161 allocs/op BenchmarkPermute2-4 5 285790686 ns/op 377401424 B/op 3628802 allocs/op BenchmarkPermute3-4 5 216943042 ns/op 377401440 B/op 3628802 allocs/op BenchmarkPermute4-4 1 1215330546 ns/op 290305888 B/op 3628817 allocs/op PASS ok github.</description></item><item><title>ABC122 D - We Like AGC</title><link>https://raahii.github.io/2019/04/03/abc122/</link><pubDate>Wed, 03 Apr 2019 23:43:42 +0900</pubDate><guid>https://raahii.github.io/2019/04/03/abc122/</guid><description>前回のコンテスト，ABC122の復習メモを残しておく．
問題 問題文 整数 $N$ が与えられます。次の条件を満たす長さ $N$ の文字列の数を $10^9$ で割った余りを求めてください。
A, C, G, T 以外の文字を含まない。 AGC を部分文字列として含まない。 隣接する 2 文字の入れ替えを 1 回行うことで上記の条件に違反させることはできない。 制約 $3\leq N\leq100$ 解法（考え方） 単純な全探索の計算量は $O(4^N)$ ．しかし「隣り合う文字列を入れ替えた時に&amp;rdquo;AGC&amp;rdquo;を含んではいけない」という制約は，新しくi番目の文字を決定するには直前の3文字のみが関与することがわかる．
ダメなケースというのは例えば
3文字: &amp;ldquo;AGC&amp;rdquo;, &amp;ldquo;GAC&amp;rdquo;, &amp;ldquo;ACG&amp;rdquo;
4文字: &amp;ldquo;A?GC&amp;rdquo;, &amp;ldquo;AG?C&amp;rdquo;
であるが，コツとして，文字列が制約を守っているかどうかを↑のように自分でパターンを書き出しすのではなく，プログラムしてあげるほうが良いということ（公式の解答でやられている）．こういう感じ．
これがまた，Goだと string は要素の入れ替えができなくて辛い感じになるのですが笑（まぁ全角文字が入ったりするとstringの要素はきちんと1文字に対応しないので，できない方が良いとも言える？）．
あとはオーバーフローするので余りを取ることを忘れないようにすること．dpテーブルの構築時，最後の和を取る部分の両方で使う．
DPによる解法 解法の方向性がわかったところで，DPで解く方法を考える．この場合，i番目に文字jを採用できる場合の数をテーブルに埋めていく．
制約の全くない単純な数え上げをするケースをまず考えると，遷移式は
$$ dp[i+1][j] = \sum_{k} dp[i][k] $$
のように書くことができ，コードは次のようになる．
この基本形を意識しながら，直前の3文字の状態を保持するためにテーブルを dp[i][j][k][l] のように拡張する．添字はそれぞれ直近3番目(j)，直近2番目(k)，直近1番目(l)を示す．そうすると遷移式は次のようにかける．
$$ dp[i+1][k][l][m] = \sum_{j,k,l}dp[i][j][k][l] $$</description></item><item><title>約数の全列挙の高速化</title><link>https://raahii.github.io/2019/03/23/divisor-enumeration/</link><pubDate>Sat, 23 Mar 2019 18:05:02 +0900</pubDate><guid>https://raahii.github.io/2019/03/23/divisor-enumeration/</guid><description>ある整数 $n​$ の約数を全て探すとき，普通は $1​$ から $n​$ までを走査するfor文で1つ1つ約数判定を行う．この場合の計算量は $O(n)​$ であり，制約が $n \leq 10^9​$ のような競プロのコンテストでは通常通らないと考える．
しかし， $n=a \times b$ を満たすような整数ペア $a, b (a \leq b)$ を考えると， $a \leq\sqrt{n}$ を満たすため，これを利用することで $O(\sqrt{n})$ で約数を全列挙できる．
ちなみにこれは Atcoder ABC112 D で使用した．実はGoで書くと $n$ が $10^9$ でも通るのだけど，まぁ増やされたらそれまでなのでまとめてみた．
ついに同解法でGoなら通るがPythonだと駄目ってのを観測した pic.twitter.com/Qd6V2PsGgX
&amp;mdash; raahii (@raahiiy) March 23, 2019</description></item><item><title>Union FindのメモとGoによる実装</title><link>https://raahii.github.io/2019/03/12/union-find/</link><pubDate>Tue, 12 Mar 2019 17:50:37 +0900</pubDate><guid>https://raahii.github.io/2019/03/12/union-find/</guid><description>AtCoder Beginners Content 120のD問題でUnionFindを使う問題が出題されたので学習した流れと実装をメモ．
問題 以下，問題ページ（D: Decayed Bridges）より引用．
問題文:
$N$ 個の島と $M$ 本の橋があります。
$i$ 番目の橋は $A_i$ 番目の島と $B_i$ 番目の島を繋いでおり、双方向に行き来可能です。
はじめ、どの 2 つの島についてもいくつかの橋を渡って互いに行き来できます。調査の結果、老朽化のためこれら $M$ 本の橋は 1 番目の橋から順に全て崩落することがわかりました。
「いくつかの橋を渡って互いに行き来できなくなった 2 つの島の組$ (a,b) (a&amp;lt;b) $の数」を不便さと呼ぶことにします。
各 $i (1\leq i \leq M)$ について、$i$ 番目の橋が崩落した直後の不便さを求めてください。
制約:
入力は全て整数である
$2\leq N \leq 10^5$ $1 \leq M \leq 10^5$ $1 \leq A_i \lt B_i \leq N$ $(A_i, B_i)$の組はすべて異なる 初期状態における不便さは0である 全探索による解法 今回の問題は$O(NM)$が通らないので全探索は無理なのですが，そもそもグラフの問題をきちんと解いたことがなかったので，まずは素直に実装してみた．前から順番に橋を落としていき，毎回独立に0から隣接行列を計算して到達可能でない島の数を数えています．</description></item><item><title>dotfilesを整備した</title><link>https://raahii.github.io/2019/02/13/update-dotfiles/</link><pubDate>Wed, 13 Feb 2019 00:13:24 +0900</pubDate><guid>https://raahii.github.io/2019/02/13/update-dotfiles/</guid><description>最近インターンが始まり、そのとき開発環境の構築に手間取ったので「やらねば…」となった．正直始まる前にやっとけやという感じなので反省．
前々からGithubで管理はしていたものの、fishに移行してからほったらかしになっていたので、今回、要らないものをぶち消して、makeとsetup.shで自動的にインストール、アンインストール、更新など出来るようにした．
ついでに、deinの設定をtomlにして、そこに各パッケージの設定を書くことで.vimrcをスッキリさせた．久しく触ってなかったBrewfileも更新して、iTermの設定もダンプしたので、大分環境構築しやすくなったと思う．めでたし．
ところで前はzshだったけれどfishはデフォルトでも使える感じなのが良いですね．若干気になる点もあって，まずtmuxとの相性が良くない印象です．コマンドの補完やpecoの画面から戻った後にコンソールがずれるのは自分だけ…？
あとは…文法が違うのもたまに気になりますが、これは慣れですね．ブラウザやSlackからコピーして実行したらシンタックスエラーでコケてあれっとなります．でも最近&amp;amp;&amp;amp;や||がサポートされたようですし，全体的にとても使いやすいので良い感じです．
ついでに，プロンプトのテーマは今んとこpureをちょっと改造したやつを使ってます．個人的に2行のやつが良くて、1行目にカレントディレクトリやgitの情報、2行目にインプットのが使いやすいと思ってます．カレントディレクトリを深く掘っても入力のスペースに影響がないからです．もしおすすめがあったら教えてください．
てな感じで、相変わらずtmux+vimで開発してます．インターンではGoを書いていて，やっぱりシンプルなところがいいなと思います．がんばります．</description></item><item><title>Conditional Batch Normalizationについて</title><link>https://raahii.github.io/2018/12/12/conditional-batch-normalization/</link><pubDate>Wed, 12 Dec 2018 15:31:51 +0900</pubDate><guid>https://raahii.github.io/2018/12/12/conditional-batch-normalization/</guid><description>Batch Normalization Batch Normalization(BN)は，内部共変量シフトを軽減することで学習を効率化する手法である．特に学習の初期段階において，前段の層の出力分布が変化すると，後段の層はその変化自体に対応する必要がでてくるため，本質的な非線形関数の学習が阻害されてしまうという問題がある．この問題は層を増やせば増やすほど深刻となる．BNは各層の出力をミニバッチごとに正規化することにより分布の変化を抑制する．また重みの初期値への依存度を下げ，正則化を行う効果もある．
具体的には，入力バッチ $\mathcal{B}= {x_1,\cdot\cdot\cdot,x_m }$ に対して
$$\mu_{\mathcal{B}} \leftarrow \frac{1}{m} \sum_{i=0}^{m} x_i$$
$$\sigma^2_{\mathcal{B}} \leftarrow \frac{1}{m}\sum_{i=1}^{m}x_i$$
$$\hat{x}_i \leftarrow \frac{x_i - \mu_{\mathcal{B}}}{\sqrt{\sigma_{\mathcal{B}}^2+\epsilon}}$$
$$y_i \leftarrow \gamma\hat{x}_i + \beta$$
のように，標準化を施し，アフィン変換を行う（新たに平均$\beta$と分散$\gamma^2$を与えるとも言える?）．この$\beta$と$\gamma$がBNの学習パラメータである．また通常，上記の操作は入力特徴マップのチャネルごとに行う．よってパラメータ$\beta$と$\gamma$は長さチャネル数のベクトルとなる．
Conditional Batch Normalization Conditional Batch Normalization1(CBN)の”Conditional”の気持ちはクラスラベルをBNのパラメータ$\gamma$と$\beta$に組み込むところにある．どのように組み込むかというと，下図(右)のように両方のパラメータをクラスラベルを基にMLPでモデル化する（だけ）．
具体的には，入力データのラベルベクトル$c$があったとき，
$$ \Delta\mathcal{B} = MLP(c),\ \ \ \Delta \gamma = MLP(c) $$
のようにクラスラベルをBNのパラメータのチャネル数に合うようにMLPで変換し，
$$ \hat{\beta} = \beta + \Delta\mathcal{B},\ \ \ \hat{\gamma} = \gamma + \Delta\mathcal{\gamma},$$
のように新たなアフィン変換のパラメータとして用いる．引用したCBNの論文では自然言語のembeddingを用いているが，SNGAN2などではクラスラベルの1-of-Kベクタを用いているはず．
なにが嬉しいのか このあたりが自分もよく把握できていないのが正直なところ．CBN自体は先程触れたSNGANをきっかけに，SAGAN3，BigGAN4でも使われているが，その有無がどれほど精度に影響するのかはあまり言及されていない．おそらく直感的には，従来のような$G$および$D$の最初の層のみにクラスラベルを与えるよりも，様々なレベルの特徴マップに対してクラスラベルを活用するように仕向けることができるのだと思う．
また，各層にクラスラベルを組み込む方法を考えたとき，最もベーシックな方法は1-of-K表現のベクトルを特徴マップのサイズ（FHxFW）に拡大してチャネル方向に結合する手法だが，かなり冗長で，畳み込み演算との相性も微妙と思われる．そういう意味ではCBNを通してクラスラベルを組み込む方が理に適っている可能性はある．</description></item><item><title>tensorboard-chainerにビデオを記録するためのPRを出した</title><link>https://raahii.github.io/2018/05/13/add-video-method-for-tensorboard-chainer/</link><pubDate>Sun, 13 May 2018 21:37:27 +0900</pubDate><guid>https://raahii.github.io/2018/05/13/add-video-method-for-tensorboard-chainer/</guid><description>機械学習における可視化ツールの1つにTensorBoardがある。これはTensorflowに付属しているソフトウェアで、学習時のlossやaccuracy、重みのヒストグラムなどを記録することができる。加えて、画像や音声などのデータも記録出来るので、生成モデルの学習でも便利に使える。
自分は普段Chainerで書いていてそのままではtensorboardは使えないのでtensorboard-chainerを使わせてもらっている。これとてもありがたい。
ただ、研究テーマが動画生成なので、動画も記録できれば便利なのに…とずっと思っていた。最近真面目にどうにか出来ないかと思って調べたら.gifの記録は元々できるらしいことがわかった。
Video summary support · Issue #39 · tensorflow/tensorboard · GitHub ということで、動画を記録できるメソッドを実装してプルリクエストを出した。初めて出したのだけれど、カバレッジやコード規約をチェックしてくれるツールに初めて触れた。外からだとテストが通らなかった理由がいまいちわからないので若干困ったけど、慣れれば便利そう。とりあえずマージはされたので良かったです。
add method &amp;ldquo;add_video&amp;rdquo; to SummaryWriter by raahii · Pull Request #2 · neka-nat/tensorboard-chainer · GitHub ということでtensorboard-chainerのadd_videoメソッドで動画記録できます。fpsも指定できます。便利。</description></item><item><title>TeXShopでバックスラッシュが円マークになる問題</title><link>https://raahii.github.io/2018/05/06/texshop-yen-mark-problem/</link><pubDate>Sun, 06 May 2018 23:46:20 +0900</pubDate><guid>https://raahii.github.io/2018/05/06/texshop-yen-mark-problem/</guid><description>これまでTeX資料はTeXShopで書いていたのだけど、最近になってoverleaf (v2)を使うようになった。そこで、TeXShopから文章をコピペしてみたら\が¥に変換されるという問題が起こった。これだとoverleafに貼り付けた時に全部置換しなくてはならない。
この現象を見た時、何故か.texの文章自体がTeXShopに書き換えられておかしくなってるのかと勘違いしてしまったのだけど、vimで開いても普通に\で表示されるので、どうやらこれはTeXShopがあえてクリップボードをいじってるらしいということがわかった。
ぐぐってみたところその通りで、TeXShopはデフォルトでクリップボードの中身の\を¥に書き換えるようだった。編集 &amp;gt; クリップボードで\を¥に変換で設定を変更できる。なぜそのような機能がデフォルトでONになっているのかはわからない。
TeXShopからソースをコピーすると\が¥でコピーされてしまう ─ TeXShop FAQ
TeXShopの設定
おそらく勘違いしたのは、これまでもOS Xでこんな感じの現象を見たことがある気がしていて、まさかTeXShop固有の問題とは思わなかったのが原因だろうと思う。とりあえず置換すれば良いか〜などと思って、
pbpaste | sed -e &amp;#34;s/¥/\\\/g&amp;#34; | pbcopy みたいなことをしていたので恥ずかしい。反射的に手っ取り早い解決方法に手をつけてしまうのではなく、一旦手を止めて問題の本質的な原因を考える癖を付けないといけないなぁと思った。もちろん当たり前でやってるつもりなんだけど改めて…。</description></item><item><title>『MEDIA MAKERS』を読んだ</title><link>https://raahii.github.io/2018/04/12/media-makers/</link><pubDate>Thu, 12 Apr 2018 00:05:28 +0900</pubDate><guid>https://raahii.github.io/2018/04/12/media-makers/</guid><description>TL;DR 『MEDIA MAKERS―社会が動く「影響力」の正体』を読んだので読書メモと感想を残しておく。本書はメディアについて書かれた本で、最近スタートトゥデイに移った田端信太郎さんが2012年に書いたもの。
「キャッシュ」から「タレント」、「アテンション」の時代へ インターネットが普及し、事業が多様化した昨今では、事業そのものを起こしたり継続していくために必要な資金は昔に比べると少なくなっている。同時に、インターネットによってあらゆる地理的な制約は取り払われ、事業や企業を成功に導くため本当に必要になるのは、タレント（優秀な人材）やアテンション（注目、影響力）であると述べられている。
そこで、「アテンション」を集め、「タレント」をモチベートするものこそがメディアなのだ、と言っている。実際にシリコンバレーではTechCrunchで取り上げられた企業にはいい人材が集まると言われているそうだ。
この章で書かれていたことは、まさに今、そしてこれからのメディアのイメージが的確に表されている感じでわかりやすかった。
メディアとは 一般には媒体であり、一時情報と受け手の間を取り持つなんらかのことを指している。テレビやラジオ、CD、Webなどあらゆるものがその定義に当てはまる。この内、本書ではいわゆるWebメディアに対して、以下の3つの分類を挙げている。
種類 特徴 例 Media型: 1対N yahooニュースなど。 Community型: N対N SNSなど。 Tool型: N対1 RSSリーダ。 ◯対◯で良い感じに整理しようとしているがよく考えるとかなり曖昧。ただ、分類するとかなり頭では整理されるのでわかりやすくはある。
また、コンテンツの側面からメディアを次の3つの軸で分類することも紹介されている。
あらゆるメディア・コンテンツを分類する３次元のマトリックス まず、フロー↔ストックはコンテンツが消費されるスピードを指す。例えばフロー性の高い情報には、新聞やニュース、ツイッターのようなものがあてはまり、ストック性の高い情報にはウィキペディア、文学作品などがあてはまることになる。
次に、参加性↔権威性は提供するコンテンツが「コントロール」されているかを指す。例えば、レストランガイドのメディアに注目した時、食べログは参加性が高く、ミシュランは権威性が高い。これらは、コンテンツがコントロールされているかどうかという点で、情報の信頼性に違いがある。
最後に、リニア↔ノンリニアはコンテンツ消費に掛かる読者の時間的な束縛性を指す。リニア性の高いメディアの代表例は映画で、上映中の約2時間、一定の空間に客を閉じ込めて情報を発信できる。反対に、ほとんどのWebメディアはノンリニアであり、好きな時に開き、好きな時にコンテンツを消費できる。おそらく以前であればテレビもリニア性の高いメディアだと言えたが、今となっては録画をすることで好きなタイミングに見ることが出来るため、メディア全体としてノンリニア化の傾向があると考えられる。
このマトリックスで重要なのは、プロットすることでメディアが分類できることだけではない。現代のメディアには、このマトリックスにおいて、極端に点が集まりすぎないように、バランス良くコンテンツを提供することが求められている。
例えばフロー性の高いコンテンツのみを発信しているWebメディアは、その時期に出した記事の注目度や話題性によって収益が大きく影響を受けてしまう。そのため、Googleの検索結果で上位に出るような、長期的に安定してPVを獲得できる記事を織り交ぜることが重要である。反対に、ストック型のメディアでも、「いつでも読めるコンテンツ」＝「あえて今読む必要のないコンテンツ」となる危険性があるため、ある程度フロー性の高いコンテンツと結びつけ、今読むべき動機をつくる必要があると言える。
メディアの影響力 まず最初に、メディアとは観察者である。メディアは人の活動や起こった出来事を文化的な情報として記録し、発信する能力を持っている。そのようなメディアの存在は、観察される側のモチベーションやアイデンティティに大きく貢献している。顕著な例として、世界最大の社内報である（と思われる）米軍の機関誌「スターズ・アンド・ストライプス」があるが、この機関誌は命がけで活動を行う兵士に、その活動が記憶され、新聞記事となり、ひいては歴史に残るのだという感覚を与える重要な役割を担っているのだと述べられている。
また、メディアには予言を実現に変える力がある。例えば、1990年代においてヨガはオウム真理教が信者の勧誘に使用したこともあり、怪しいイメージであった。しかし、2004年にYoginiが創刊されたことによってムーブメントが起こり、実際にヨガを始める女性が増えた。このように、メディアには読み手の潜在的な欲望を喚起し、現実のもとする力があると言える。
Yogini（http://www.manduka.jp/html/page6.html より引用） メディア運営で大事なこと 1つは読者の性質＝ペルソナを理解することである。読者の性別、年齢、趣味、職業などを認識することで、どのようなコンテンツを提供すると見てもらえるのかを知ることが出来る。これは実際に、アンケート調査やユーザーインタビューを行う現場を見たことがあるので納得感がある。
もう一点、サイトの分析を行い売上の構造を理解することである。例えば、Webメディアにおいては広告によるマネタイズがメジャーであるため、PVが有名な指標である。
あらゆるメディア・コンテンツを分類する３次元のマトリックス 当たり前なことではあるが、このように木構造でもれのないように分割して表していくと、施策との対応付けもしやすく、今後使えそうだな思った。</description></item><item><title>『イシューから始めよ』を読んだ</title><link>https://raahii.github.io/2018/04/09/start-from-the-issue/</link><pubDate>Mon, 09 Apr 2018 01:30:57 +0900</pubDate><guid>https://raahii.github.io/2018/04/09/start-from-the-issue/</guid><description>TL;DR 『イシューから始めよ』を読んだ。
メモ 仕事の価値 価値のある仕事は、解の質とイシュー度（取り組む問題の質）の2軸で捉えることができ。る。良い仕事をするためには、解の質が高いだけでなく、解こうとする問題に価値があることが求められる。
ただこの時、よくやってしまう失敗がある。それは、安直に労働量を増やすことによって解の質を高めようとする行為である。これは本書では犬の道として紹介されている。
本書より引用。画像は http://mugentoyugen.cocolog-nifty.com/blog/2010/12/post-a444-1.html より転載
犬の道を通って生産性を高めても、長続きしない上、そのやり方は人に教えることが出来ないという大きな問題がある。また、特に事業においては、価値の無い課題にどれだけ取り組もうと無意味である。よって、あなたはまずイシュー度を高めることに注力しなくてはならない。イシューを洗い出し、価値の高い問題から順に取り組むことこそが高い生産性を生む。
イシューの探し方 重要なのはイシューだということはわかった。ではその良いイシューというのはどのように探せばよいか。
本書では、まず相談相手をみつけることが大切であると述べている。なぜなら、アイデアがたくさんあっても、それが受け手にとって本当にインパクトのあるものかどうかはその分野や領域に精通していなければわからないからだ。
イシューを見極めるためには「実際にインパクトがあるか」、「説得力のあるかたちで検証できるか」、「想定する受け手にそれを伝えられるか」という判断が必要となり、ここにはある程度の経験と「見立てる力」が必要になる。
この「実際にインパクトがあるか」、「説得力のあるかたちで検証できるか」、「想定する受け手にそれを伝えられるか」という3つの観点は、一見当たり前のように感じるが、研究を例にとると、自分がこの1年間で感じたことと重なる部分が多い。
例えば私は「研究（提案）を特徴付けるような応用例を考えるように」と指導教官に度々アドバイスを受けていたが、それはまさに「想定する受け手にインパクトを伝えられるか」というか点に大きく関わっている。また、実験結果を報告した時に「どういう見立てでその実験をやったの？」「その実験は一体何を検証したいの？」というツッコミを受けることもあった。問題解決においては、検証したい仮説がしっかり絞り込まれていなかったり、検証を繰り返すうちにに本来の目的が意識から外れたりといったことが簡単に起こる。その問題に陥ると、途端に意味のない実験をやってしまったりするということになる。このような点からも、常に今やっていることに対して「これは説得力のあるかたちで検証できているか」という視点を持つことが重要だと思う。
また、良いイシューには以下のような性質がある。
本質的な選択肢である 深い仮説がある 答えを出せる 本質的な選択肢とはそれが右なのか左なのかによって、最終的な結果に大きく影響することを意味する。また深い仮説とは、これまで常識として信じられていることを疑ったり、物事の新しい共通性、関連性、法則を見出すような仮説のことを指す。
そのようなイシューを発見するためには、
一次情報に触れる 基本情報をスキャンする 集めすぎない・知りすぎない ことがすすめられている。
最後に、1つイシューを見つけたら、それに対してまずなんらかの立場を取って仮説を立てることがすすめられている。仮説を立てることによって、それに紐付くサブイシューを発見できるだけでなく、それを検証するために必要なデータが見えたり、結果が解釈しやすくなったりする。仮説を立てる際にはしっかりと文章に落とし込んだ方が良い。
感想 本書では問題解決の方法としてイシュー分析（=イシューの発見+ストーリーラインの設定）を挙げている。前半がイシューの発見、後半がストーリーラインの組み立て方という構成だった。
最初の1章のところで犬の道が紹介されていて、「何故イシューが重要なのか」というところはすごく納得感を持って読めたが、読み進めるに従って、取り上げられる例があまりピンとこず、納得感が薄くなってしまった。特に、良いイシューについての説明のところで、これまでの定説や常識を覆す例として天動説が取り上げられていたが、さすがにもっと良い例があるのでは…という感じがした。他にも研究や事業を基にした例もいくつかあげられていたけれど、うまく飲み込めなかったので、そこは実践する中で気になったらもう一度本書を開くって感じで良いかな思いました。</description></item><item><title>草津温泉へ行った</title><link>https://raahii.github.io/2018/04/01/kusatsu-onsen/</link><pubDate>Sun, 01 Apr 2018 12:13:45 +0900</pubDate><guid>https://raahii.github.io/2018/04/01/kusatsu-onsen/</guid><description>初めて草津温泉に行った。草津は群馬県吾妻郡にある。適当に浦和辺りまで出て、特急草津号で長野原草津口（2時間くらい）まで出て、最後はバス（20分）で草津温泉の最寄り駅という感じでした。
特急草津号は指定席にするかどうか迷ったけれど、とりあえず自由席買っておいて、実際に電車に乗り込んで座れなさそうだったら車掌さんに追加料金を払って指定席にするのが良さそうでした。直前の特急券の混雑度で自由席の混み具合もおおよそ予想できるのと、できるだけ始発駅に近いところに乗れば良さそうです。追加料金の場合もSuicaで払えるので便利。一方帰りは結構混んでいたので、荷物持って並ぶの面倒くさいと思う場合は指定席の方が楽そうです。
草津温泉といえば湯畑と湯もみが有名（どうしてもテロマエ・ロマエのシーンが思い浮かんでしまう）。湯畑はその名の通り畑をイメージしたもので、畝を模した温泉の通り道みたいなのがあって独特な風景でした。湯もみの方は湯もみショーというのが午前午後で3回ずつあったんだけど時間合わなかったので見ず。（しかも¥600くらいしたはずなので、家でYoutubeで見ます…笑）
近くの西の河原公園でも温泉が流れる川はあったけれど、湯畑の”畑に見立てる”というコンセプトは独特の良さにつながっているし、湯もみも板を転がしてお湯を混ぜてるだけなんだけど、ネーミングセンス良いなと思ったので、ブランディング(?)のうまさを感じました。
あとはところどころに足湯があってゆっくりできるのと、もちろん夜は温泉をいくつか巡ったりして、かなりリラックスできました。ただ湯が熱すぎてどうしようもない温泉がぼちぼちあったのでそこはちょっと残念。笑　ちなみにこの時期だと気温がまだ若干低くて、最低気温がまだ氷点下なので、温泉回る時は湯冷めしないように気を付けたほうが良いですね。
その他写真など…。
&amp;lsquo;草津&amp;rsquo;がどうしてもうまく捉えられない。 3Fに図書館があり温泉のことを勉強できるらしい… なんかセブンイレブンが小豆色でかっこいい。 湯畑良い。夜は湯気に対して青色のスポットライト当てたりしてるのでまたかなり違う雰囲気になります。
足湯も良かった。 ここ行きそびれたんだけど、多分快適にコード書ける。 あとグルメの方は宿のご飯があったのであまり食べずという感じでしたが、おそば、焼き鳥、お饅頭、ソフトクリームなどが美味しそうな感じでした。食べたものとして、気になってた揚げ饅頭はおいしかったですが、温泉卵ソフトクリームは卵の味しなくて普通のバニラアイスでした。笑　次行くときはお蕎麦とかいろいろ食べたいですね。</description></item><item><title>『イノベーション・オブ・ライフ』を読んだ</title><link>https://raahii.github.io/2018/03/13/innovation-of-life/</link><pubDate>Tue, 13 Mar 2018 16:00:38 +0900</pubDate><guid>https://raahii.github.io/2018/03/13/innovation-of-life/</guid><description>TL;DR 『イノベーション・オブ・ライフ』を読んだので感想と読書メモを残しておく。
感想 友人に勧められて本書を読むことにしたが、個人的には今後も振り返りたくなる内容で良本だと思った。特にインパクトが強いのは第一部で、私は来年度から本格的に就活に向き合わなければいけないので、「どんなキャリアを築くことが人生の幸せにつながるのか」の考え方を学べたのは良かった。（もちろんこれは就活に限らず今後ずっと考えてるべきことだと思う。）
本書を読んで、これまで高専・大学と情報工学を学んできたことを活かし、ソフトウェアエンジニアになりたいという気持ちはより強くなった。一方で、自分の視野の狭さを感じるシーンは多々あるので、もっと視野を広げればやりたい職種は他にもあるんだろうなと思った。残りの学生生活は短いが、社会人になるまでは創発的な機会を見逃さないよう、様々なことに興味を持つ姿勢を持ちたいと思った。
他にも、本書の最初の方で研究員のダイアナにまつわるエピソードがあり、そこでのマネジメントという職業についての言及は印象的だった。
だが、ダイアナが研究所で過ごす毎日が、彼女の家庭におよぼす影響について思いをめぐらせるうちに、こう確信するようになった。人のためになる仕事をするには経営者になればいいのだと。マネジメントとは、立派に実践すれば最も崇高な職業の一つだ。経営者は自分の元で働く一人ひとりから、毎日八時間ないし、十時間という時間を預かる立場にある。また、従業員が毎日仕事を終えて、良い一日を過ごした時のダイアナのように、動機づけ要因に満ち溢れた生活を送っているという満足感をいだきながら家に帰れるよう、ひとりひとりの仕事を組み立てる責任を担っている。
上記の引用では主語が経営者となっているが、この主張はチームや組織の上に立つ役職であれば同様に当てはまると思った。これを読んで、マネジメントとはまさに「人のためになる仕事である」と考えを改めたし、これくらい高い視座で働けたら本当に素晴らしいと思った。
いまのところ、本書に載っている理論は簡単な例を通してわかった気になっているものが多いので、また時間を空けて読んでみたい。重要なのは「何を考えるか」ではなく「どう考えるか」を知ることだとあり、たしかにその通りなのでちゃんとそこまでできればと思う。
内容（読書メモ） 本書は「自分の人生を評価するものさしは何か？」を見出すために、経営学の理論を用いて、次の3つの問いに答えようとするものである。
どうすれば幸せで成功するキャリアを歩めるだろう？ どうすれば伴侶や家族、親族、親しい友人たちとの関係を、ゆるぎない幸せのよりどころにできるだろう？ どうすれば誠実な人生を送り、罪人にならずにいられるだろう？ 各部では経営学の理論とその理論が引き起こす直感的な事例が紹介される。
本書で紹介する理論は、人間の営みに対する深い理解──「何が、何を、なぜ引き起こすのか」──に支えられており、また、世界中の組織によって徹底的に検証、活用されてきた。
優れた理論は、「気が変わる」ことがない。一部の企業や人にだけあてはまり、ほかにはあてはまらないということはない。
本書では各章で一つずつ理論を取り上げ、それを一つの問題にあてはめるという構成を取っている。
第一部： 幸せなキャリアを歩む 「幸せなキャリアを歩めているならば、きっと毎朝、自分のやっていることをやれる幸せをかみしめながら目覚めることができる」
優先事項（あなたがキャリアで最も重視すること）について 動機づけ理論。
衛生要因と動機づけ要因をちゃんと分けて捉えること。自分にとっての動機づけ要因をみつけること。
理想のキャリアを探す計画、計画と思いがけない機会のバランスについて 発見志向計画法。
意図的戦略と創発的戦略を理解して行動すること。複数の創発的機会に対しては、「どの仮定の正しさが証明されればよいか」を考え選択すること。
戦略の実行、資源配分について 資源配分のパラドックス。
資源配分のプロセスを意識して管理すること。正しい戦略を脳内で描いていたとしても、人は無意識のうちに、短期的に見返りが得られる安易な選択をしてしまう。
達成動機の高い人たち陥りやすい危険は、いますぐ目に見える成果を生む活動に、無意識のうちに資源を配分してしまうことだ。
同級生たちは昇進や昇給、ボーナスなどの見返りがいますぐ得られるものを優先し、立派な子供を育てると言った、長い間手をかける必要があるもの、何十年も経たないと見返りが得られないものをおろそかにした。
第二部： 幸せな関係を築く 「家族や親しい友人との、親密で愛情に満ちた、揺るぎない関係は、人生で最も深い喜びを与えてくれる物の一つだ。」
資源配分の優先順位、人間関係の性質について 良い資本と悪い資本。
キャリアの中だけでなく、キャリアとその他のもの（本章では家族や友人）においても、資源配分を自分の優先順位とすり合わせて行わなければならない。この時注意しなければならないのは、家族や子供を相手にする場合は、（企業やキャリアと異なり）思うようにコントロールできないことが多いこと、そして、人生においては投資の順番を好きなように変えられる物ばかりではないということ。（本章は理論でいう所の「成長」と「利益」が人生においてどう対応するのかうまく理解できなかった。「時間や労力の量」と「幸福」だろうか。） モノや人の役割について 片付けるべき用事。
ミルクシェイクの企業施策の例にもある通り、人間関係においても自分がどのような用事を片付けるために雇われているかを自問することが重要である。自分の中で勝手に決めつけるのではなく、真に相手が大切にしていること、必要としていることを理解しようと努めることが大切である。そして、その役割を実際に実行に移し、献身的にならなければならない。献身は愛情に転化する。そのために時には自分の優先事項や希みを後回しにする必要があるかもしれない。同じように相手にも献身的になれる機会を与えよう。
片付けるべき用事のレンズを通して結婚生活を見れば、お互いに対しても最も誠実な夫婦とは、お互いが片付けなければならない用事を理解した二人であり、その仕事を確実に、そしてうまく片付けている2人だとわかる。
人の能力について 資源、プロセス、優先事項の能力モデル。</description></item><item><title>『スタンフォード式　最高の睡眠』を読んだ</title><link>https://raahii.github.io/2018/03/08/stanford-awesome-sleep-method/</link><pubDate>Thu, 08 Mar 2018 14:04:10 +0900</pubDate><guid>https://raahii.github.io/2018/03/08/stanford-awesome-sleep-method/</guid><description>TL;DR 『スタンフォード式 最高の睡眠』を読んだ。睡眠の質を最大限に高めるためには、最初の90分の睡眠の質を高めることを心がけることが大事。 そのために具体的に何をすべきかというと、
寝る前はできるだけ脳みそ使わず、リラックスしとく 寝る90分前にお風呂に入る（90分も時間がないときは、ぬるめのシャワーか足湯） 朝起きたら陽を浴びる アラームは起床時間の20分前と起床時間の2つかける 要点 レム睡眠とノンレム睡眠 人は寝ている間に深い睡眠（ノンレム睡眠）と浅い睡眠（レム睡眠）を周期的に繰り返す。しかし、この深くなったり浅くなったりする波形の振幅は就寝から起床にかけて徐々に減少していく。そのため著者は、単に最所の90分の（ノンレム）睡眠の質を高めることに注力することで睡眠の質が高められることを主張している。
交感神経と副交感神経 人間の体では意思とは関係なく自律神経が常に働いている。体温を維持し、心臓を動かし、呼吸し、消化し、ホルモンや代謝を調整するのが自律神経である。この自律神経には活動モードの交感神経と、リラックスモードの副交感神経がある。日中は交感神経が優位だがノンレム睡眠中は副交感神経が優位となる。よって夜になったらスムーズに副交感神経が優位の状態に移行しなければ、最初の90分の質を確保することはできない。
そのため、寝る直前まで仕事をして頭を回転させていたり、ネットを見て脳が興奮状態にあるようなことはできるだけ避けた方が良い。（なので、夜はこういう作業をするのがおすすめ）ちなみに、ブルーライトが悪いと巷でよく言われるが、実際には相当目を近づけない限り問題にはならない。とにかく、できるだけリラックスすることが重要らしい。
体温と脳 体温と脳の状態は入眠に大きな関わりがある。例えば、質の良い睡眠を取っているときには体温が下がることがわかっている。人間の体温は深部体温と皮膚温度に分けて考えるとわかりやすい。入眠前には手足が温かくなり皮膚温度が上昇する。これにより手足から熱が放散され、深部体温が下がることになる。
よって、この皮膚温度が上昇→深部体温が下降の流れを意図的につくることで睡眠の質を上げるのがポイントとなる。そこで入浴である。深部体温には温度の急激な変化（あるいは一時的な変化？）に対してそれ打ち消そうとする働きがある。すなわち、入浴によって深部体温が上昇すると、入浴後には深部体温は下がろうとするのである。これを利用し、就寝の90分前に入浴することによってスムーズに眠れるということになる。また、就寝まで90分も確保できない場合には、同じような変化をゆるやかに起こすという意味で、ぬるめのシャワーを浴びることで代替できる。また足湯の場合には深部体温ではなく意図的に皮膚温度を上げることで熱放散を促す（ことで深部体温を下げる）という意味で、終身の間際でも効果があると述べられている。
サーカディアンリズム 良い睡眠と良い覚醒は2つでセットである。サーカディアンリズムとは、24時間のリズム（地球の自転周期）のことであり、要は体内時計である。日中は活発に活動し、夜はぐっすり眠るという流れはこのリズムが正しく体内で働くことで起こるものである。
このサーカディアンリズムは陽の光を浴びることで調整される。そのため、朝起きたら陽の光を浴びることが重要である（有名）。また、目を覚ますという点では、朝シャワーを浴びること（深部体温を上げるため。ただし上げすぎると、夜の入浴と同じで深部体温はその後下がろうとするため、逆に午前眠くなるので注意）や、朝ご飯をきちんと食べる（咀嚼し体内時計をリセットする、汁物で深部温度を上げる）ことが挙げられている。
睡眠サイクル 自分としては効果がある実感はこれまで全然なかったのだけれど、たまに本当に90分サイクルを考慮して寝てますと言う人がいる。確かに、この90分という睡眠サイクルは人間の平均としてはそうらしいので、この理論が合う人が一定数いるのはわかる。が、そもそも睡眠サイクルというのはそこまで厳密な周期で起こるものではなく、普通、起床時間に近づくにつれて周期が短くなり、頻繁にサイクルが回るようになる。（なので、むしろそれが安定しているならば、就寝と起床をしっかりリズムよく行えており、かなり良い睡眠なのでは？という気もする）加えて、周期の90分という時間には個人差がある。よって、無条件に90分という理論は成り立たないのがほとんどである。
では、睡眠サイクルを考慮した覚醒をするためにはどうすればよいかというと、アラームを2つの時間でセットすることを本書では推奨している。その2つの時間とは、起床時間と、その20分程度前である。ここで、1回目の方はアラーム音は小さく、短いものにしておく。これにより、朝短時間で回っている睡眠サイクルから、レム睡眠（覚醒に近い状態で目覚めやすい時間）のタイミングをより確実に捉えることが出来る。なぜなら、レム睡眠の場合は覚醒に近く小さな音でも聞こえやすいため、1回目のアラームが聞こえれば無理なく起きることができる。一方、1回目で起きなければそのときはノンレム睡眠であるため、その20分後の2回目のアラームで無理なく起きれるためである。これも少しメソッドとしては違うがこの前の「ためしてガッテン」でもやっていた。
その他（メモ） 睡眠医学のエビデンスを持ってはっきり「こうだ」と言えることはまだ少なく、加えて睡眠は個人差が大きいので万能法はなかなかない。 理想の睡眠時間は遺伝子で決まるため個人差がある（エンペラーペンギンの眠らない特性、アメリカの男子高校生のギネスの不眠記録などの例より）。 ショートスリーパーは短命（ショウジョウバエの例より）。 「睡眠不足」という言葉は古い。感覚的に「睡眠負債」という言葉が正しい。 睡眠負債を返済すればパフォーマンスは確実に上がる（スタンフォードのバスケットボールの選手の例より）。 しかし睡眠負債の返済には滅茶苦茶時間がかかる（例えば40分の睡眠負債を返すのに、毎日14時間ベッドに居るのを3週間続ける必要があるという例より）。 夢の中で作業ができるという人がいる（梨大の森勢先生はよくそんなことを言っている）が、それは本書では不可能と言っている。 どうしても夜遅くまで作業しなければならない場合、最初の睡眠サイクルが最も深い睡眠であることから、とりあえずいつもどおりの時間で寝てしまってから、早めに起きるほうがよいらしい（現実的かというと微妙だけど）。 ランチは食べても食べなくてもその後眠い。よく、「食事をとると、消化のために腸に行く血流が増えて、脳に行く血流が減るため」といわれるが、どんな状況でも脳血流は第一に確保されるためその説は偽、とのこと。 仮眠を取るなら20分。それ以上取ると認知症のリスクが高まる。 睡眠の役割
脳と体に「休息」を与える　 「記憶」を整理して定着させる 「ホルモンバランス」を調整する 「免疫力」を挙げて病気を遠ざける 「脳の老廃物」を取る 感想 自分は予定がないと平気で8〜12時間くらい寝てしまう上に、目覚めがすっきりしないことが多いので本書を読んでみた。とりあえず、前のエントリで書いたmiband2を最近使っていなかったので、またこれで睡眠計測が始めようかなと思った。morninはカーテンが手で開けられなくなるのでやっぱだめですね。笑
あと、自分はほぼ毎日必ず夢を見るのだけれど、これが自分にどういう影響を起こしているのかは本書を読んでも解決できなかった。本書によれば、人はかならず睡眠時に夢を見ており、しかもレム睡眠とノンレム睡眠時で毎回異なる夢を見ているそうだ。ただ、ほとんどの場合は起きる直前のレム睡眠の夢しか覚えていない、ということらしい。おそらく、全体的に睡眠が浅いということなのだろうか…。
睡眠中に見る夢の意味と睡眠との関係では、
「最近夢をよく見る（覚えている）ことが多い」という場合は、起きる前の明け方付近に“浅い睡眠が多くなっている”可能性があります。
と書かれているで、やはり質の悪い睡眠してるんでしょうね…。まじで毎日見ますからね。
最後に、そういえば本書に書いてあったこれ、ちょっとびっくりしました。
脳は直接、頭蓋骨に収まっているわけではない。「脳脊髄液」という保護液につかっているので、転んで頭を打っても、脳が骨に直接ぶつかって傷つかずに済むのだ。 小さな「脳のプール」ともいえる脳脊髄液はおよそ1500cc。1日4回、600ccほど入れ替わっている。
結構入れ替わるんですね。
とりあえず冒頭に書いたこと実践しつつ、日付変わる前に寝て朝ちゃんと起きたいですね。</description></item><item><title>Kinectを用いたRGB-Dデータセットのまとめ</title><link>https://raahii.github.io/2018/03/01/kinect-rgbd-dataset/</link><pubDate>Thu, 01 Mar 2018 18:23:10 +0900</pubDate><guid>https://raahii.github.io/2018/03/01/kinect-rgbd-dataset/</guid><description>はじめに 卒研でRGB-Dデータを使う研究をやっていたので、その時に調べた内容について軽くまとめます。
タイトルでは&amp;rdquo;Kinectを用いた&amp;rdquo;となっていますが、実際はそこに拘りはありません。ただ、研究分野でかなりよくKinectが使われているので、RGB-Dに関わる研究を探す場合には同時にKinectの文脈でも探したほうが良いと思います。Google Scholarでも&amp;rdquo;kinect&amp;rdquo;の方がよくヒットします。
Google Scholar &amp;#39;rgbd&amp;#39; Google Scholar &amp;#39;kinect&amp;#39; さて、実際にデータセットについてまとめようと作業を始めたのですが、せっかくなので表にまとめようと思い、早々に挫折しました。そこで、調べる中で見つけたRGB-Dデータセットのサーベイ論文をシェアすることにします。
文献リスト まず、Kinectから取得されるRGB-Dデータ（及び音声データ）の応用をまとめている論文があります。Kinectから取ったデータの使い道のイメージをつかめると思うのでおすすめです。
A Survey of Applications and Human Motion Recognition with Microsoft Kinect 論文 RGBD datasets: Past, present and future (2016) データセットの種類（タスク）毎に表で整理してありわかりやすいです。データセットの説明や作成年だけでなく、サムネイルが付いていて、形式（Video?/Skelton?）についても言及があります。 表の例（本項の論文より引用） RGB-D datasets using microsoft kinect or similar sensors: a survey. (2017) これも種類に応じて章分けしてまとめてくれています。一応表もありますが見づらいです。個々のデータセットに対し、サンプル数やラベル情報を簡潔に文章でまとめてくれています。最初のツリー画像が良い感じです。 データセット木（本項の論文より引用） RGB-D-based Action Recognition Datasets: A Survey (2016) アクション認識に絞ってまとめられているのですが、文章でも表でもかなりよくまとめられています。とうか逆にタスクを絞ったからこそまとめやすいのかもしれませんね。ラベル数とサンプル数で図に落とし込まれているのもわかりやすかったです。 データセットの比較の図（本項の論文より引用） A Survey of Datasets for Human Gesture Recognition (2014) これはジェスチャ認識に絞ってまとめられたものです。これも表あるのでわかりやすいです。あと、Availability (Public, Public on Request or Not Yet)の項もあるのが特徴です。</description></item><item><title>3DGANをchainerで実装した</title><link>https://raahii.github.io/2017/10/25/chainer-implementation-3dgan/</link><pubDate>Wed, 25 Oct 2017 20:14:00 +0900</pubDate><guid>https://raahii.github.io/2017/10/25/chainer-implementation-3dgan/</guid><description>タイトルの通り，3DGANのchainer実装をgithubに上げた．当初はKerasで書いていたが良い結果が得られず，ソースコードの間違い探しをするモチベーションが下がってきたので，思い切ってchainerで書き直した．
実はmnistなどのサンプルレベルのものを超えてちゃんとディープラーニングのタスクに取り組むのは今回が初めてだった． ChainerによるGANの実装自体は公式のexampleやchainer-gan-libが非常に参考になった．
モデル 3DGANはその名の通り3Dモデルを生成するためのGAN（Voxelです）．Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modelingで提案されているもの．前回の記事でも触れた．
構造はDCGANと同様で200次元のベクトルよりGeneratorでサンプルを生成，Discriminatorでデータセット由来かGenerator由来か（real/fake）を分類しそのロスをフィードバックする．
Generatorは以下の図（論文より引用）のようなネットワークで，Discriminatorはこれを反転したようなモデルになっている．各ネットワーク内では3次元畳み込みを使用する．最適化手法はAdamで，論文ではDiscriminatorがバッチを8割以上正しく分類できた場合はパラメータを更新しないようにしたとあった．
3Dモデル データセットにはShapeNet-v2を用いた．このデータセットには様々な種類の3Dモデルが収録されているが，今回は椅子のモデルのみを抽出した．椅子はおよそ6700サンプルが収録されており，ファイル形式は.binvoxが直接収録されていたのでそれを使用した．
ただ，6700サンプルの3Dデータを全てメモリに乗せることはできなかったため，初期実装では毎回のループで読み込み処理を行っていた．その後，.binvoxファイルのヘッダー読み込みなどが不要であり，処理速度に支障があると感じたので事前に.h5に書き出して使うようにした．
ShapeNet-v2に収録されているデータのサンプルを示す．
実装 3DGANの実装をやろうと決めてから，実験を始める前に3Dモデルの取扱について理解するためのツールをつくっていた．主にはSimple Voxel Viewerで，.binvox形式について理解したり，matplotlibでボクセルをどうやってプロットしようかということについて考えていた．
64x64x64のボクセルを可視化するため，最初はmatplotlibの3Dplotを試したが，scatter plotやsurface plotを使うとマインクラフトのような箱を集積した見映えのプロットが実現できない上，一つ描画するのに数十秒かかることがわかった．そこからまず自作してみようと思いTHREE.jsを使ってSimple Voxel Viewerを作ってみた．ところが結局こっちもいくらか高速化は試したものの，64x64x64のサイズでも密なボクセルになるとメモリーエラーが起こってしまいうまく動作しない問題が起こった．加えて当たり前だがPythonのコードにも組み込めない．
そうして結局，matplotlibの3D volxe plotを採用した．しかしこの関数はまだリリースされていないため（2017/10時点），githubから直接インストールする必要があった．動作も遅いままだが妥協することにした．
ネットワークはKerasやTensorflowなどによる実装がいくつかgithubに上がっていたためそれらも参考にしつつ実装した．加えて，有名なGANのベストプラクティスのページを参考にした．ポイントをかいつまむと以下のような感じで実装した．
ランダムベクトルzは論文では一様分布だったがガウス分布を使った． GeneratorはDeconv3D+BN+ReLUの繰り返しで，最後だけsigmoid． DiscriminatorはConv3D+BN+Leaky-ReLUの繰り返しで，最後だけsigmoid． Chainerの公式のexampleを真似してロスはsoftplusを使って実装．ただ，実はsigmoid + Adversarial lossがsoftplusと同じなのでDiscriminatorの最後のsigmidは不要なのだが，加えた方がうまくいった(謎)． 結果 成功例 良さげな感じを出すためにきれいなものを集めた．学習の初期段階ではでたらめなものが出力されるが，徐々に椅子が形成され，50エポックから100エポックくらいでましなものが出来た．
学習の途中では椅子とは独立した無意味なかたまりのオブジェクトが所々に浮かんでいたりしたが，それが消えてくるとかなり見栄えが良くなっていった．
失敗例 ボクセルが全て1になったり0になって消滅したりした．今回幾度も学習をさせてみて，初期の段階からほぼ1なボクセル，あるいはほぼ0なボクセルが生成されたり，規則的なパターン（模様）を持つボクセルが生成されたりすると多くの場合失敗となるという微妙な知見を得た．
また，ボクセルが消滅したらその後復活しないこともわかった．ただこれは実装のところで述べたようにロスが間違っているせいかもしれない．
わかったこと GANはロスは全くあてにならない．生成結果が全て． zはガウス分布から取ってきたほうが良さそう． 学習を調整する(Discriminatorのlossやaccを見て更新しないなど）のはうまくいかないと感じた． 今回のコードではsigmoid + adversarial lossをsoftplusで実装しているので，Discriminatorの最後のsigmoidは不要なはずなのだが，誤って入れていたらうまくいき，外したらうまくいかなくなった．動きゃ勝ちみたいなところがあって釈然としない． 論文では1000エポック学習したとあったが100エポック行かないくらいでかなり形になった． また，今回はGANのベストプラクティスの内，以下のトリックは実践しても効果がなかった.
Discriminatorに学習させるミニバッチをrealのみまたはfakeのみにする．(項目4) GeneratorにもDiscriminatorにもLeaky-ReLUをつかう．(項目5) GeneratorにADAMを使ってDiscriminatorにはSGDを使う．(項目10) GeneratorにDropoutを使う．(項目17) 所感 実装に関して，やはりコード自体はKerasの方が圧倒的に簡単にかけるようになっているなと感じた．モデルのインスタンスを作ってバッチをmodel.</description></item><item><title>ボクセルデータを描画するツールを作った</title><link>https://raahii.github.io/2017/10/09/tool-preview-3d-voxel-data/</link><pubDate>Mon, 09 Oct 2017 01:32:00 +0900</pubDate><guid>https://raahii.github.io/2017/10/09/tool-preview-3d-voxel-data/</guid><description>最近、GANで3Dオブジェクトを生成する論文を読んでいました。下のスライドは雑なまとめなのですが、前者が所謂3D-GANと呼ばれている論文で初めて3Dオブジェクトの生成にGANを適用した論文です。後者はその3D-GANを応用した研究のようです。
どんなものか知るには著者らが公開している動画が非常にわかりやすいです。静止画と同じようにGANを3Dモデルにも適用できそうだということがわかります。
ということでgithubにあがっている実装などを参考に実際にやろうとしているところなのですが、これらの手法では主に3Dオブジェクトを「ボクセル」として扱っています。
このボクセルというのは「体積 (volume)」と「ピクセル (pixel)」を組み合わせたかばん語らしいのですが、要は画像と同じ要領で3Dモデルを3次元配列に格納して表したものです。イメージとしてはマインクラフトみたいな感じです。
CGでは頂点情報や法線、テクスチャなどを保存する.obj, .3dsなどが有名（らしい）ですが、それらに比べると非常に簡単で取り扱いやすくなっています。
その一方でボクセルデータを保存する形式には.binvoxがあるのですが、メジャーではないためかツールが少なめです（まぁただの3次元配列だしね…）。ざっくり探したところ以下のものは便利そうだなと思いました。
.binvoxを3次元配列に変換: dimatura/binvox-rw-py(python)
.objや.mtlを読み込んで変換し、ボクセルとして可視化: Online Voxelizer(web)
ただ、単に.binvoxファイルをアップロードしてすぐに中身を見れるツールはなさそうだったので今回はそれを作ってみました（というエントリです）。ここから試せます。
github.com
ボクセルは形式そのものがシンプルなのでmatplotlibを使って3dplotするのでも良いのですが、結構重いんですよね。three.jsを使えばWeb上でマウスでグリグリできるインターフェースを簡単に作れるので楽しいですし、いつかフロントエンドで使えるかも…。
先程紹介したOnline Voxelizerに比べると動作がかなり遅いしメモリも結構消費してしまうのでそこが今後の課題です。うーん…おしまい。</description></item><item><title>LaTeXiTで数式が表示されない問題</title><link>https://raahii.github.io/2017/07/01/latexit-bug/</link><pubDate>Sat, 01 Jul 2017 23:12:00 +0900</pubDate><guid>https://raahii.github.io/2017/07/01/latexit-bug/</guid><description>LaTeXiTはTeX数式を画像に変換できるツールですが、ついさっき使ったらプレビューに数式が表示されず、というか数式画像の生成自体に失敗しているみたいで全く使えないという事態に遭遇しました。
思い当たったのは最近brew updateした時にghostscriptがアップデートされたことだったので確認。
brew info ghostscript ghostscript: stable 9.21 (bottled), HEAD Interpreter for PostScript and PDF https://www.ghostscript.com/ /usr/local/Cellar/ghostscript/9.21_1 (8,484 files, 98.2MB) Poured from bottle on 2017-05-23 at 13:32:45 /usr/local/Cellar/ghostscript/9.21_2 (717 files, 64MB) * Poured from bottle on 2017-06-22 at 00:29:33 From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/ghostscript.rb ==&amp;gt; Dependencies Build: pkg-config ✔ Required: little-cms2 ✔ ==&amp;gt; Requirements Optional: x11 ✔ ==&amp;gt; Options --with-x11 Build with x11 support --HEAD Install HEAD version 確かに06/22に更新している。なんとなく怪しいのでバージョンを下げたらなおった。</description></item><item><title>Ruby(Rails)でGoogle Analytics APIを使う</title><link>https://raahii.github.io/2017/05/04/ruby-google-analytics-api/</link><pubDate>Thu, 04 May 2017 01:03:00 +0900</pubDate><guid>https://raahii.github.io/2017/05/04/ruby-google-analytics-api/</guid><description>今回RubyでGoogle Analytics APIを利用する機会があったのですが、思ったより情報が少ない上、必要な鍵ファイルやトークンがよくわからず時間を取られたので以下に手順をまとめておきます。
Developers Consoleでプロジェクト作成・APIを有効化 まずはおなじみのやつですが、Googleのセットアップツールを利用するとパパッと完了できます。画面の表示に従ってプロジェクト作成→認証情報に進む→OAuthクライアント作成→完了と進めます。
注意してほしいのが認証情報のところで、自分は以下のようにしました。最後の認証情報のダウンロードは不要です。
サービスアカウントの作成 次にサービスアカウントページを開いて、プロジェクトを選択→サービス アカウントを作成→（サービス アカウントの名前を入力）→新しい秘密鍵の提供→作成を順にクリックします。公開キーと秘密キーのペアが生成されるので、client_secrets.p12というファイル名で保存します。
また、サービスアカウントのIDを次で使うのでコピーしておいて下さい。
Googleアナリティクスのユーザーにサービスアカウントを追加する 準備作業の最後として、アナリティクスデータの表示と分析の権限をサービスアカウントに付与します。自分のGoogleアナリティクスのページを開き、左タブの管理＞ビューの列のユーザー管理に進み、権限を付与するユーザーとして先ほどのサービスアカウントのIDを入力して追加します。
また管理＞ビュー設定にあるビューIDをこの後使うのでコピーしておいて下さい。
必要なパッケージをインストール RailsであればGemfileに追記します。
gem &#39;google-api-client&#39;, &#39;~&amp;gt; 0.11&#39; bundle install 単にターミナルから使うのであれば以下。
gem install google-api-client キーと設定ファイルを配置 そうしたら、ga_config.ymlという名前でyamlファイルを作成し、中身を記述します。以下を自分の情報と置き換えて下さい。
サービスアカウントのID:
Google Developers Consoleの左上のハンバーガーメニュー＞IAMと管理＞サービスアカウントで確認できます。
アナリティクスのビューID:
自分のアナリティクスのアカウントより、左タブ＞管理（歯車アイコン）＞ビュー設定より確認できます。
サービスアカウントのキー:
サービスアカウント作成の時に得たclient_secrets.p12を適当に配置してパスを記述します。
サービスアカウントのキーのパスワード:
特別設定していなければ&#39;notasecret&#39;のままでOKです。
データを取得 以下がメインのスクリプトです。そのまま使う場合はとりあえずga_config.ymlやclient_secrets.p12と同ディレクトリに置くと動くと思います。
start_dateやend_date、metrics、dimension、sortなどは必要に応じて変更して下さい。データの取得方法は共通だと思うので下記など他の情報を参照して下さい。
github.com
Railsアプリで使う場合 今回紹介したのはただのスクリプトですが、例えばランキングを作りたいといった場合にはアクセス数を利用してモデルに順位を付与したいと思います。そこで使えるのが、Railsの環境を読み込んだ上で任意のRubyコードが実行できるrails runnerです。またそういった独自のスクリプトみたいなものはlib/tasksに配置してrakeタスクとして使うほうが正しそう(?)です。またgithubで公開する場合などはキーファイルなどをリポジトリに含めないように注意して下さい。</description></item><item><title>HoloLensを軽く触ってみた印象</title><link>https://raahii.github.io/2017/02/04/hololens-review/</link><pubDate>Sat, 04 Feb 2017 00:51:00 +0900</pubDate><guid>https://raahii.github.io/2017/02/04/hololens-review/</guid><description>大学の授業でオムニバス形式の授業があり、そこでたまたまHoloLensを触る機会があったので少し思ったことを書く。
ただ実際には授業中の講師の方の5分程度のデモを見て、授業後に3分ほど自分で体験しただけなので、ちゃんとコンテンツに触れられたわけではない。
まず最初の印象として、見た目がかなりスタイリッシュなデバイスで驚いた。単体で見ると結構かっこいい。またHoloLens自体にはWindowsが乗っており、CPUなどもデバイス本体に属しているのでケーブルでつなぐことなく単体で動作するらしい。ますます軽快なイメージを持った。ただその見た目とは裏腹に地味に重かったので長時間の使用は疲れるかなと思った。
装着すると、半透明のディスプレイがありガラス越しに周りが見えるようになっている。VRではなくMR（Mixed Reality）が体験できるデバイスなんだな、とその時理解した（恥ずかしい）。ディスプレイには、ARで空間上にメニューやオブジェクトが表示されており、中央にはカーソルが存在している。カーソルは顔が向いている方向（視線方向）に対応しているらしく、このカーソルを対象に合わせつつ、およそ自分の視界に入るくらいの範囲で「手でものをつまむ」ような仕草をするとクリックが実行できる。
実際にWebブラウザが表示されていたのでクリックしてページ遷移をしてみた。で、体験した内容はたったそれだけで、空間には他にもオブジェクトがあったのだけれど触る時間がなかった。今度触る機会があったらゲームとかやってみたい。
それで授業を受けてとても驚いたのが、とにかく周りが「HoloLensで何かが変わる」という雰囲気だったこと。たしかにHoloLensが将来的に眼鏡くらいのサイズになれば、電脳コイルみたいな世界ができて凄そうという想像はできるけれど、今日触った感じだと衝撃みたいなものは特になかった。唯一感じたのはその操作インターフェースのやりにくさで、頭部を動かしてカーソルを動かすというのは単に自分が見たい方向を見る以上に細かい動作が必要なので、ストレスフルに感じた。クリック動作もあまり感度が良くなくて違和感があった。
また家に向かいながら、今の主流なゲーム機や急速に普及したスマホを見ても、現状のHoloLensのような操作インターフェースではあまり日常的な普及はできないのでは、と思った。というのも、ゲーム機のコントローラーにしても、スマホのタッチディスプレイにしても、操作には物理的な接触とフィードバックがある。これは多分快適な操作に重要なのではと思う。HoloLensのインターフェースでは、そこに「人がものをつまむ」というメタファーを感じることはできても、やはり宙を掴む感じがするというか、違和感があると思った。
ただ、普及して慣れれば問題ないみたいな話かもしれないので、実際のところはよくわからない。もうちょっと色々考えなら今後の動向をチェックしたいなと思った。あと周りの人にも色々何を思ったか聞いてみようと思った。
ということで今回はHoloLensを触れてナウい感じの授業だったのでよかった。</description></item><item><title>「ヘルシープログラマ」を読んだ感想</title><link>https://raahii.github.io/2017/01/03/review-healthy-programmer/</link><pubDate>Tue, 03 Jan 2017 10:14:00 +0900</pubDate><guid>https://raahii.github.io/2017/01/03/review-healthy-programmer/</guid><description>ヘルシープログラマ ―プログラミングを楽しく続けるための健康Hack
作者: Joe Kutner,Sky株式会社玉川竜司 出版社/メーカー: オライリージャパン 発売日: 2015/07/23 メディア: 単行本（ソフトカバー） この商品を含むブログ (9件) を見る
感想 本書はプログラミングを職業とする人が、一日中座り続けるという習慣から慢性的に運動不足に陥ることの危険性や、よく引き起こす疾患の事例とその対策について説明している。一方、タイトルから匂い立つ&#34;プログラマは如何にして健康になれるか“というような方法論だけにとどまらず、単にプログラマとしてより良いパフォーマンスを発揮するためにどのように身体と付き合うべきかということも書いてある。
私は大学の図書館でたまたま本書を見つけ、また最近ではタイピングによって右手首に負担をかけていることを認識していたので手に取ったが、本書の前半で述べられている
「習慣」そのものについて 脳と身体の関係について プログラマがよく引き起こす疾患について などのトピックは、今現在なんらかの疾患に陥っている人や、いかにも不健康な見た目をした職業的プログラマだけでなく、デスクワークを日常的にする人なら誰が読んでもためになると感じたのでおすすめしたいと思った。
特に私の印象に残っているのは、ウォーキングが脳にもたらす効果について説明した2章である。1章で既に脳と身体のつながりについて触れられ、物理的な健康が頭脳に対して直接的にメリットをもたらすことが強調されている。そして2章では、フェルマーの最終定理に8年間注力し、実際にその証明を成し遂げたAndrew Wilesを例に、作業の前後にウォーキング（エクササイズ）を行うことで集中力、記憶力、創造力を高めることができると述べられている。
これは、プログラマがコードを夜遅くまでハックしたり、最新の技術書を読んだりすることと同様に、ウォーキングが我々の能力を強化するための最高の方法の一つであることを示している。
それ以外にも、習慣のメカニズムやスタンディングデスクの真実を知ることも出来る。これらは多くの人々が関心のある一般的なトピックだと思う。最後に、本書で紹介されていた健康のユニットテストに対する自分の状況をメモして、今後も意識したいと思う。
健康のユニットテスト 踊り場まで階段を上がると息が切れるか 1時間以上立ち上がることなく座り続けることが、日常的にあるか 昨年、仕事に差し支えるほどの腰痛、首痛、肩痛、手首痛が生じたことがあるか 先週、コンピュータの画面を見た時に、ドライアイ、目の充血や炎症、あるいは目の焦点を合わせづらくなったことがあったか 先月、苦しくなるほど食べすぎたことが複数階あったか 今日、直射日光に当たった時間は10分以下だったか 過去5年間に、虫歯の数は増えたか 見をかがめて靴紐を結ぶのは苦しいか 過去5年間でズボンのサイズが明らかに大きくなったか 目次 1章　変化を起こそう 2章　健康のブートストラップ 3章　椅子よさらば？ 4章　アジャイルなダイエット 5章　頭痛と眼精疲労の対策 6章　腰痛への対策 7章　手首痛への対策 8章　実践的なエクササイズ 9章　個室の外で考えよう 10章　健康のリファクタリング 11章　チームを作ろう 12章　進め、健康なプログラマ 追記 メモ。</description></item><item><title>昨年買った睡眠に関わるアイテムの感想メモ</title><link>https://raahii.github.io/2017/01/01/gadget-review-2017/</link><pubDate>Sun, 01 Jan 2017 00:32:00 +0900</pubDate><guid>https://raahii.github.io/2017/01/01/gadget-review-2017/</guid><description>こんばんは。だらだら書いていたら新年が明けてしまいました。あけましておめでとうございます。
本記事では今年買った少しテックな2つのアイテ厶について感想をメモします。
Mi Band 2（Xiaomi）
Xiaomi Mi Band 2 有機EL液晶搭載，時刻チェック可能 ライトセンシティブ スマートリストバンド 心拍計 Bluetooth2.0 ワイヤレススポーツブレスレット 軽量 IP67防塵防水 活動量計 歩数計 睡眠計 アラーム 連続動作20日間 Android4.4/IOS7.0対応 アプリ [並行輸入品]
出版社/メーカー: Xiaomi メディア: エレクトロニクス この商品を含むブログを見る 公式サイト
一つ目はXiaomiが出しているスマートウォッチ、Mi Band 2です。Mi Band 2はMi Bandの後継機で、LEDディスプレイを搭載しています。主な機能としてはデジタル時計、睡眠計測、心拍数計測、歩数計測、そしてスマホ通知との連動です。
購入の動機は、この値段で睡眠計測機能が使えるという点です。またMi Band 2になってディスプレイが搭載されたことによりセンサーだけでなく腕時計として使えるようになったのも大きかったです。
購入したのは10月なのでおよそ2ヶ月間利用したのですが、これという欠点はほとんどなく、サイズも小さいし、軽いし、充電は平気で5日間位持つので、値段を考えると素晴らしい商品だと思います。
睡眠計測 まず、一番気になっていた睡眠計測の機能ですが、就寝・起床ともにかなり正確に時間を記録してくれるので驚きました。計測した結果はXiaomiの公式アプリで確認でき、Deep Sleep時間とLight Sleep時間も計測してくれます。Deep Sleepの時間はどの程度正確なのかはわかりませんが、一応自分の睡眠の質の目安となります。私は毎日7〜8時間位寝ますが、Deep Sleepは2〜3時間で推移しています。この部分はどのくらい信頼できる数値なのか、個人差はあるのか、などがわかると良いなと思います。SNSとかないのかな笑。
一方、この機能の欠点はこれを手に装着して寝なければいけないことです。私の場合、最初から付属しているシリコンのバンドを使っているため、毛布に引っかかったり布団に押し付けながら寝ると手に跡ができたりして、気になります。少なくとも気持ちよくはないので邪魔だなと思うシーンが多々あるのが難点ですね。
というわけで、睡眠計測はまぁまぁ使えています。最近は機械学習とかloTとか叫ばれていて、ライフログを溜めること自体が面白いのですが、ちょっと面倒くさい面もあります。計測したデータは今のところ、月ごとの平均睡眠時間を見て「寝すぎたなぁ」とか「寝るor起きるの遅いなぁ」と思う程度ですが、改めて見てみるとやはり自分の生活習慣が如実に表れていると感じます。なので「来月から早起きしよう」とか「夜寝る前はブルーライトシャットアウトしよう」といった生活習慣を変える試みと併せて使うと数字でフィードバックが返ってくるので嬉しいと思います。アプリからデータを見てもいいですが、csvでエクスポートできるのでもっとちゃんと分析も出来ると思います。
時計 Mi Band 2は普通に時計として使えます（使っています）。ただLEDディスプレイなのでずっと点いているわけではなく時間で消灯します。そのため腕のひねりを検知して時計を確認したタイミングで点灯するようになっています。ただ微妙にタイミングが遅く少し気になります。また、文字も小さいので、時計としては及第点という感じです。
またアラーム機能もあります。本体が振動して知らせてくれます。ただあんまり強い振動ではないので起きられない上、バッテリーの寿命を減らす原因になるみたいなので普段はあまり使いません。意外に便利なシーンが電車移動で30分くらい寝るかというときです。音じゃなく振動なので使いやすいです。
歩数計 歩数計としても使えます。一日の目標を設定して達成すると知らせてくれます。座りがちなので是非みなさんも意識的に歩きましょう笑
防水 またMi Band 2はiPhone7と同じIP67の防水性能があります。お風呂ぐらいなら付けたまま入れます。最初はわざわざ付けて入るか？と思っていましたが、寒くなってきてからシャワーに入る時間が長くなってきたので時間を意識できるように付けて入るようになりました。こういう少し便利なところが気に入っています。
スマートフォン連携 私はほとんど使っていませんがスマートフォンの通知を振動とともにMi Band 2のディスプレイに表示することもできます。ただ任意の文字情報を表示することはできないため、ただ通知がきたとわかるだけです。</description></item><item><title>Rubyの文法のミニメモ</title><link>https://raahii.github.io/2016/12/22/ruby-language-features/</link><pubDate>Thu, 22 Dec 2016 01:18:00 +0900</pubDate><guid>https://raahii.github.io/2016/12/22/ruby-language-features/</guid><description>Railsでサービス作ってみたは良いものの、Rubyに関する理解が結構おろそかになっている。なので、今回は基本的だけど未だに理解できていない部分を簡単にまとめる。
Rubyはすべてがオブジェクト Rubyに入門すると一度は耳にする「Rubyは完全にオブジェクト指向的な言語である」という文言。入門したときはあまり深く考えていなかったので、よく考えると「いやいやPythonにだってクラスはあるんだからオブジェクト指向は使えるじゃん」とか思っていた。Pythonのオブジェクト指向は後付けのものだということを聞いたことがあるので、まぁそんな程度の違いだろうという曖昧な理解だった。
しかし、改めて調べてみてRubyが完全にオブジェクト指向的であることが簡単にわかる例があったので書いておく。
# Rubyが完全にオブジェクト指向的であるというということは # 1などの定値もオブジェクトになっているということ p 1.class # =&amp;gt; Fixnum # 1がオブジェクトならmethodを持っているよね p 1.methods # =&amp;gt; [:%, :&amp;amp;, :*, :+, ・・・] # +というメソッドがあるなら足し算はこう書ける p 1.+(1) #=&amp;gt; 2 # 数字がオブジェクトのおかげでこういうRubyらしい書き方ができる 10.times {|i| print i} # =&amp;gt; 0123456789 なるほど。これで前よりは少し理解が進んだ。
シンボルとハッシュ Rubyにはシンボルという型がある。:(変数名)で定義でき、注意点は
:symbol == :&#34;symbol&#34; # =&amp;gt; true となること。
このシンボルであるが、よくハッシュで使われる。ハッシュはkeyとvalueで構成され、一般的にkeyは文字列で定義される。
しかし、keyを文字列として扱うと、valueを参照（keyの識別）する際にコストの高い文字列処理を行わなければならなくなる。ここでシンボルである。
端的にいうと、シンボルは任意の名前をつけることの出来る整数である。例えば:symbolというシンボルはなんらかの整数と紐付けられており、常に一定となっている。よってシンボルをkeyとすることで、文字列処理を行わなければ行けなかったところを、コストの低い整数処理に置き換えることが出来る。
わかりやすい例として、以下のようなコードを実行してみると、同じ文字列でも異なるオブジェクトidとなることがわかる。異なるオブジェクトなのだから当然といえば当然である。
a = &#34;test&#34; b = &#34;test&#34; a.equal?(b) # =&amp;gt; false 一方、シンボルはオブジェクトによらない。
a = :test b = :test a.</description></item><item><title>Fashion Shop Mapというwebサービスをつくった</title><link>https://raahii.github.io/2016/11/26/web-service-fashion-shop-map/</link><pubDate>Sat, 26 Nov 2016 01:36:00 +0900</pubDate><guid>https://raahii.github.io/2016/11/26/web-service-fashion-shop-map/</guid><description>タイトルの通りwebサービス作りました。またしてもGoogle Mapを使ってしまった。
https://fashion-shop-map.herokuapp.com/
サービス概要 今回作ったものは、ファッションのショップの位置情報を検索することができるサービスです。これを使うことで、複数のショップの位置を同時に地図にプロットして見ることができます。
ユーザーの操作はとてもシンプルで、検索したいショップと都道府県を選択してボタンを押すと、選択された都道府県内にある店舗が地図上にマッピングされます。
機能としてはシングルページのwebサイトに近いくらいシンプルです。現在は主にセレクトショップを取り扱っており、以下のようなショップが登録されています。
ロゴ 名前 ロゴ 名前 BEAMS UNITED ARROWS UNITED ARROWS BEAUTY&amp;amp;YOUTH UNITED ARROWS green label relaxing URBAN RESEARCH URBAN RESEARCH DOORS SHIPS EDIFICE 417 EDIFICE JOURNAL STANDARD coen A.P.C. BShop SENSE OF PLACE by URBAN RESEARCH HARE RAGEBLUE GLOBAL WORK FREAK&#39;S STORE モチベーション まず服が好きなので、それに関わるサービスを作りたいなと思っていました。</description></item><item><title>ロゴの利用について少し調べて学んだこと</title><link>https://raahii.github.io/2016/11/17/web-copyright-in-japan/</link><pubDate>Thu, 17 Nov 2016 20:41:00 +0900</pubDate><guid>https://raahii.github.io/2016/11/17/web-copyright-in-japan/</guid><description>はじめに
今作っているちんけなwebサービスがほとんど出来上がって久しいきたのですが、よし公開するかと思った矢先、「サービスにメーカーのロゴが使われているってまずいのではないか」という疑問が湧き、何故今まで気づかなかったのかと愕然としました。
情報系の学部に通っていると知的財産権に関わる授業を受けますが、そういう系の授業は大体「睡眠薬がまかれたのではないか」という有様なので、内容についてはあまり記憶がないです笑。ただ、授業のおかげでそういうセンサーが少しでも芽生えたかもしれないことは良いことだと思います。
とにかく、いくらミニマムなサービスだとしても作り手としては留意すべき点だし、今後にも役立つだろうと思い少しだけ調べたので、簡単にまとめようと思います。
ロゴに関わる権利とは 私は最初、著作権が問題になるのではないかと思いました。ところが、調べてみるとどうやら商標法なるものが問題となるようでした。商標法とは、名の通り商標登録されたものを保護するための法であり、まさにロゴのことでした。
そもそも、商標法より先に例えばマクドナルドのページの利用規約などを見てみると、
5 . 知的財産権について
当サービスのすべてのコンテンツ（著作物、肖像、キャラクター、その他の一切の情報）は、当社もしくは、その委託先等が著作権等の知的財産権、使用権、その他の権利を有しています。著作権法で認められている範囲を超えての使用はお控え下さい。
6 . 禁止事項
当サービスのご利用にあたり、利用者は以下の行為を行わないものとします。違反した場合には、当サービスの利用を予告なくお断りさせていただく場合がありますので、あらかじめご了承下さい。
（中略）
(2) 特許権、実用新案権、商標権、意匠権、著作権、著作隣接権、肖像権、トレードシークレット、プライバシー、その他他者の権利、財産を侵害する行為、または侵害するおそれのある行為。
というような記載があります。これらはどのサイトでも必ずある記載で、「ア、オワタな」と一瞬思ったのですが、もう少し調べることにしました。
商標としての使用であるか否かが重要 調べ続けるうちに、弁護士・弁理士の方にアドバイスをもらえるQ&amp;amp;Aサイトのページがいくつかヒットしました。眺めていると「ロゴの使用が『商標としての使用』に該当しなければ問題ない」というような書き込みを発見。
詳しく調べると、「自他商品識別機能、出所表示機能等を有するような使用の仕方でなければその商標権を侵害しているとはいえない」ということがわかりました。
これを私の理解でざっくりいうと、商標法の侵害に当たるのは「他者が登録した商標を用いて、自分のサービス（商品）に付し、商標（めじるし）として使うこと」だと言えます。よって、ロゴを用いてサービスを作ったとしても、それが明らかにそのメーカーについて言及した記述や説明に過ぎないという場合は問題にならないということです。良かった…。
ロゴの著作権は？ とりあえず、明らかに商標法に抵触していることはなさそうだということがわかりましたが、それでは著作権はどうなのかと思ったのでこれも調べました。調べるとすぐにこんな記事が。
www.nikkeibp.co.jp
これによると、
著作権は、「感情または思想を創作的に表現したもの」で「文芸・学術・美術・音楽」に発生する権利で、著作物を創作した時点で著作者に自動的に発生するとされています。
（中略）
次に、商標について考えてみます。商標とは、シンボルマーク、ロゴタイプ、ロゴマーク、キャラクター、特徴的な商品のデザイン、看板など、企業の商品やサービスを他社と区別するためのもので、「企業の業務上の信用」を視覚化したものだととらえられています。商標法により、商標権の保護対象となるもので、商標権が登録され設定されている期間、専有的にこれを使用することができます。
「商標」には種類があり、扱いが異なります。アルファベットなどの文字で構成されるロゴタイプ、ロゴマークは、基本的に著作権は認められていません（「Asahiロゴマーク事件」）。ただし、商標のうち「シンボルマーク」にはその美的表現の程度により著作権が発生する場合があり、「キャラクター」には著作権が発生するとされています。熊本県のキャラクター「くまモン」は、著作権を買い上げた県が著作権使用料を無料にしたことで、さまざまな商品に展開されました（使用には県の許可が必要です）。
と書かれており、基本的には商標は著作権では保護できないため気にする必要はないようです。ただ、ロゴにキャラクターが載っている場合は注意が必要みたいですね。そんなに多いケースではないと思うのでひとまず安心です。
さいごに 商標について気になったので調べてみました。結果、ちゃんと商標法の条文を読んだわけではありませんが「どうやら問題なさそうだ」ぐらいはわかりました。
また、もし近い将来一エンジニアとして会社に勤めることになれば、真摯に取り組まなければならないテーマだということも感じました。これからも個人的に何かを作るときには、想像力を働かせて、少しでもその場で調べる癖を習慣にしていければと思いましたまる
参考 ホームページ上でのロゴ使用について・・・ - 特許・商標・著作権 - 専門家プロファイル
商標権侵害の考え方～アウトライン・「使用」の意義 | 弁護士法人クラフトマン IT・技術・特許・商標に強い法律事務所(東京丸の内・横浜)
ロゴマークに著作権はない──企業デザインと知的財産権 | 小さな組織の未来学</description></item><item><title>find | xargs grep を知る</title><link>https://raahii.github.io/2016/10/26/find-xargs-grep-script/</link><pubDate>Wed, 26 Oct 2016 11:10:00 +0900</pubDate><guid>https://raahii.github.io/2016/10/26/find-xargs-grep-script/</guid><description>はじめに
今回は頻繁につかうのに理解していないスクリプトがあるのでそれについて簡単に書こうと思います。そのスクリプトがコレです。
find . -name &#34;*.py&#34; -print0 | xargs -0 grep -i &#34;pync&#34; どんなことをするスクリプトかご存知ですか？
これはカレントディレクトリ以下にあるファイル*.pyの中からpyncという単語を含むものをリストアップするワンライナーです。すなわちこういうことです。
find . -name &#34;&amp;lt;検索対象のファイルネーム&amp;gt;&#34; -print0 | xargs -0 grep -i &#34;&amp;lt;探したい単語&amp;gt;&#34; 前から何度か使っていたものの、たまにしか使わないしすぐ忘れるだろうということで、すぐにシェルスクリプトファイルで保存し「ブラックボックス化」していました。最近になって特に多用するようになってきたのでちゃんと理解しようと思います。
解読 まず、パイプの左側のfindの部分について。
find . -name &#34;&amp;lt;検索対象のファイルネーム&amp;gt;&#34; -print0 言わずもがなfind .でカレントディレクトリ以下の全てのディレクトリ・ファイルを列挙します。よくファイルを探す時に使いますね。
そして -name &#34;*.&amp;lt;拡張子&amp;gt;&#34;とすることで検索対象のファイルを限定します。ファイルをたくさん持つディレクトリを検索するのであれば時間を短縮できます。加えてこれを使わずに実行すると、サブディレクトリもリストアップされてしまい、パイプ以降に渡されるとエラーを起こします。結果が見づらくなるのでそれを防止する効果もありますね。
最後に-print0ですがこれは全く使ったことのないオプションだったのでmanで見てみると、
-print0 This primary always evaluates to true. It prints the pathname of the current file to standard output, followed by an ASCII NUL character (character code 0).</description></item><item><title>最近の開発環境におけるTips</title><link>https://raahii.github.io/2016/09/30/recent-reports-sep/</link><pubDate>Fri, 30 Sep 2016 02:02:00 +0900</pubDate><guid>https://raahii.github.io/2016/09/30/recent-reports-sep/</guid><description>近況
夏休みが今週いっぱいで終わる 今週rubyとrailsに入門した 開発環境 ruby、railsは現在チュートリアルをやってるような感じで特に書くことはないのだけれど、それらを始めてから急に同時に多くのファイルを編集する機会が多くなってきました。なので、最近気づいたコードを書くときのコツ、vimのいい感じの使い方を少しメモしておきます。
① NERDTreeと画面分割を使う プロジェクトのルートでNerdTreeを開きながら水平分割(s)を使うといろんなファイルをすぐ開けて便利です。加えてNERDTreeはファイルの作成/削除などの基本操作もできるのでvimの中で結構完結します。
② タブページ機能を使ってファイルをうまく仕分ける Model、View、Controller、設定ファイルといったコードのかたまりをタブを利用して分けてあげると使いやすい。もちろんタブ間の移動は使いやすいキーにバインドしておく必要があります。ファイルを新しいタブで開くときもNERDTreeはtでできるので楽ちんです。
③ 作業の中断・開始にはセッションを使う これまで書いたようにファイルは整理しながらたくさん開くので、必然的にその状況を保存したいなぁとなります。以下の記事にわかりやすく書いてあるのですが、vimでは:mksで現在開いているバッファやウィンドウの状態を保存してくれます。記事では~/.Session.vimに保存されると書いてあるのですが、私の環境では標準でカレントディレクトリ（./Session.vim）に作成されました。この方がわかりやすいので私は好きです。 keyamb.hatenablog.com
④ エディタとシェルはもう分けちゃったほうがよい vimを開いている状態からrailsやgitのコマンドを打つためにシェルに戻るのは結構めんどくさいです。今までは:shellと打って抜けるやり方が好きでしたが、最近vimを抜けてからzshが入力を受け付けるまでが結構遅いことに気づき、iTermのウィンドウをそもそも分けることにしました。zshがちょっと重いらしく、あんまり使いこなせてもいないのでbashにしようかなと思ってます。あと、VimShellとかfugitiveはあんまり合いませんでした。
所感 やっぱり大きめのモニタあると捗る エディタとシェルを分けちゃうとvimの存在意義が薄れてきている気が vimは操作といい色々柔軟できるけどそろそろIDEも試してみようかな…</description></item><item><title>imgcatコマンドで遊ぶ</title><link>https://raahii.github.io/2016/09/21/show-lgtm-using-giphy-and-imgcat/</link><pubDate>Wed, 21 Sep 2016 23:10:00 +0900</pubDate><guid>https://raahii.github.io/2016/09/21/show-lgtm-using-giphy-and-imgcat/</guid><description>近況
インターンに行ってJavaを用いたWebアプリケーション開発を経験してきました。
もともとサーバーサイドの方の知識は0に近く、データベースとかサーバーってめんどくさそう…くらいの認識でした。今回その辺りのコーディングをいくつか担当させて頂き、Webアプリの全体像が見えた気がします。とりあえず、Webアプリ開発を一通り経験したというのはとても大きな意味がありました。
また、チーム開発が初めてだったこともあり、Gitを初めて実践的に使った他、かんばんやKPTといったアジャイル的な開発手法にも触れられたのも楽しかったです。
imgcatコマンド がらっと話は変わりますが本題。みなさんimgcatというコマンドをご存知でしょうか。おそらくiTerm上でしか動かない…と思いますが、ターミナル上で画像を表示するコマンドです。
これ、一見ネタのようなコマンドですが、Qiitaにはこんな記事が投稿されています。
qiita.com
いや、やっぱりネタかもしれない。
こんなimgcatですが、もしかしたらこれってすごい力を秘めているのではないかと私は思いました。というのも、黒い画面というのはどうしても地味になりがちで、長時間コーディングをすると精神的に良くないと感じるからです。これを使えばもしかしたらターミナルが賑やかになるかもしれない...！
GIPHYからGIF画像を取得して表示する ということで、いつまでも自分の手元にある画像を見ていても面白くないのでネットから拾ってきます。最初はGoogle画像検索を使おうと思っていましたが、最終的にGIPHYというサイトのAPIを使ってGIF画像を取ることにしました。そうです、imgcatでGIF画像を表示するとちゃんと動くんです！できたものはこんな感じ。
猫。
ピカチュウ。
カートマン。
GIPHYは海外サイトなので日本語では検索できませんが、結構素材は豊富っぽいです。
ソースコード Pythonで書きました。簡単ですが...。 コレくらいだったらwgetとかでワンライナーで書けたりしそう。どうだろう。
手順はこんな感じです。
コマンドライン引数で検索ワードを受け取る
GIPHYのAPIを使って画像を検索し、結果からランダムに一つをピックアップする
選んだ画像のURLにHTTPリクエストを投げてかえってきた画像データをそのままバイナリで標準出力に流す
imgcatにリダイレクトする
GIPHYのAPIはGoogleのCustom Search APIと違って（おそらく）制限がないのと、現在public beta keyを出してくれてるので使うのが楽でした。
また、今回使った検索以外にもトレンドの画像の取得や絵文字からGIFへの変換など色々できるようで今度使ってみたいなと思います。
応用例 さて、そもそもこれを作ったワケというのは、黒い画面を眺め続け疲弊した心に安らぎをあたえてやることでした。
一つ考えた例としてgit commitする度に好きなテーマの画像が表示されるようにします。zshrcに以下を追加。
すると…
予想外に地味😇。　今回は検索ワードを&#34;LGTM&#34;にしましたが、猫でいいかも。git commitをmycommitに置き換えなきゃいけないのはスマートじゃないですね。
ということで、みなさんもくれぐれも心のケアは大切にして下さい（適当）。
終わりに こういうの作ってる最中はいいんだけど、作り終わった後の賢者タイムの辛さ…ね…。
所感 拾ってくる画像
Twitterからとってきても面白いかも。
最後の使い方の例のところ改良の余地有り
元々git commitしたら画像を表示するというのは、たまたま見かけたcdしたらlsするという記事にヒントを得たものでした。なので本当はgit commit() { \gitcommit &#34;</description></item><item><title>Chrome extensionに入門した</title><link>https://raahii.github.io/2016/08/12/window-operation-chrome-extension/</link><pubDate>Fri, 12 Aug 2016 00:21:00 +0900</pubDate><guid>https://raahii.github.io/2016/08/12/window-operation-chrome-extension/</guid><description>http://dotinstall.com/lessons/basic_chrome_v2dotinstall.com
前回の記事でスターをつけてくださった方のブログを眺めていたらChromeの拡張機能を作っていて、Chromeの拡張機能ってHTML/CSS/JSだけで作れるのか！ということを知りました。せっかくの機会なので入門して自分なりに簡単な拡張機能を作ってみました。
モチベーション シンプルにChromeを使っていて不便だと思う部分を解決するために作りました。
私の考える問題点 例えば、Chromeでブラウジングしていて、最初はあることについて調べていたんだけど、気づいたら全く違うテーマのページを開いていた、なんてことありませんか？特に自分は学校の課題で調べ事してたんだけど退屈すぎていつの間にかネットサーフィンしてた、みたいなのがよくあります。
そんな時、そのウィンドウには、もともと調べていたテーマに関するタブと、新しく調べ始めたテーマに関するタブが混在してしまっている状態です。こういう時、テーマによってウィンドウを分けたくなります。そんなときみなさんどうしますか？単純にやるとこう↓なりませんか。
（左側3つのタブと右側2つのタブを切り分ける様子）
このようにブラウザって複数のタブに対してはあまり柔軟に操作できないなと感じます。とくにウィンドウをまたぐと辛い。そこでタブ（ウィンドウ）操作を柔軟にする拡張機能をつくりました。 つくったもの github.com
　そのような流れでChrome拡張機能の入門として↑を作りました。インポートすると右上にタブっぽいアイコンが出てきますので、これをクリックすると使うことができます。この拡張機能は、タブのかたまりに対して主に分割する機能（split）と、保存する機能（store、bookmark）で合計3つの機能を備えています。
split: 現在開いているタブを含め右側のタブを新しいウィンドウで開く
一つのウィンドウに存在する異なるテーマのタブ群を分割(split)します。splitボタンを押すと、今開いている(activeな)タブを含め、そこから右側にあるタブを新しいウィンドウで開きます。
store: 今開いているウィンドウをWebStorageに一時保存
保存したいタブ群をまずsplitで切り出した後に、保存したいウィンドウでstoreボタンを押すとあなたのlocalStorageにウィンドウが保存されます。
他のデバイスで見たりするわけじゃないけど、少しの間しまっておきたい時に使います。取り出すときは、先ほどのstoreボタンがretrieveボタンになっているのでそれを押して下さい。
bookmark: 今開いているウィンドウのタブを全てブックマークする
store機能は使っている端末のlocalStorageに保存するので、他の端末では開くことができません。もちろんスマホのChromeでは拡張機能自体が使えないので共有できません。そんなとき今開いているウィンドウの全てのタブを一括ブックマークできるのがbookmarkボタンです。
bookmarkボタンを押すとパスの設定画面が現れます。新しいフォルダ名とそのフォルダをどこに置くかを決めてsaveボタンを押してください。もしフォルダ名が空であった場合、新しくフォルダは作らずそのまま展開してブックマークされます。
課題 store機能の改善
保持したウィンドウの情報を見れる機能、もう要らないって場合に捨てられる機能があったらよいかも。
splitできるならjoinも？
splitの逆で複数のwindowを1つにまとめられる機能があってもよいかも。
バグの修正
初回のウィンドウに限ってsplitがうまく動かない時がある。 jsの非同期処理による弊害をあんまり考慮せず作ったのでそのあたりを見直したい。 popup.htmlを改良する
最低限のデザインにしていきたいんだけど、レイアウトの仕方について要勉強。この手のページを作るとき、大体HTML/CSSを書くのにJavaScriptと同じくらい時間かかるのもどうにかしたい。 名前
tabs_splitterなんかしっくりこない。英語的にもおかしい気がするしtabをキーワードとして残したい。
所感 ボタンの名前をどう表記するのがベスト？
単に split？それとももっと詳しく open right tabs in a new window？あるいは日本語で ◯◯◯？どれがわかりやすいんだろう。</description></item><item><title>Google Maps APIを使った標高の可視化</title><link>https://raahii.github.io/2016/07/24/visualize-elevation-along-the-route/</link><pubDate>Sun, 24 Jul 2016 15:50:00 +0900</pubDate><guid>https://raahii.github.io/2016/07/24/visualize-elevation-along-the-route/</guid><description>タイトルの通りGoogle Maps APIを使って、出発地点から目的地点までの高低差を可視化する簡単なサイトを作ってみました。
ルートに沿った標高の可視化
github.com
きっかけとしては、新生活に伴い、家から大学までのルートの高低差を知りたかったからです。
個人的な話ですが、今年から大学に進学しまして一人暮らしを始めました。一人暮らしにあたっては家賃はもちろんですが、家から学校までの距離が一つ重要な要素ですよね。近いに越したことはないとは思いますが、スーパーやコンビニのあるなしで利便性が大きく変わるので、少々遠くても自転車で通えればOKです。まぁ10km前後になると夏は汗だくで授業を受けるはめになりますが...。
そんなとき、加えて重要なのが、高低差じゃないでしょうか。アップダウンが激しいと辛いですよね。そんな具合で春頃に実際にそれを調べたいなと思った時、何故かそういうサービスがあまりなかったのでGoogle Maps APIを使って自分で作って可視化してみてました。
最近ではロードバイクやクロスバイクに乗る人が増えて、ランニングする人も多くなってきているので、結構使いたい人はいるんじゃないかと思っています。元々自分なりに春先には作っていたものを綺麗にしてWebサイト作りの練習として公開してみました。とはいってもHTML/CSS/JSだけの本当に簡単な試作品のレベルですが。
先ほど言ったとおり、このサイトではGoogle Maps APIを使っていて、出発地と目的地を入力すると自動でルート検索が行われて、ルートに沿った高低差が可視化されます。もともとそういう関数があるのでものすごく実装は簡単なんですが、ルートにそって高低差が出せるってとこが重要です。APIは無料で使う分にはup to 25,000 map loads per dayなのでサービスとしてはちゃんとしたものはできていませんが、今後ルートの候補を選べるようにしたり、ルートごとの高低差の違いを同時に見れたりしたら便利かなと思っています。
とまぁ、そんなこんなで最近はWeb系に興味がでてきたので、夏に集中的に勉強できたらなと思います。制作実績がないとインターンも厳しいので、コツコツ夏に勉強して冬のインターンを狙っていきたいと思います。それでは。
今よくよく探してみると、
地図検索 - NAVITIME
ルートラボ - LatLongLab
Flattest Route
と、機能や完成度・他サービスとの連携はまちまちですが既存のものも意外にありますね。(笑)
NAVITIMEは坂の少ない／多いルートを選べ、かつ所要時間も出ていて素晴らしいです。ただちょっと図が小さめ。ルートラボはパッと検索するというよりは、ユーザー同士が作ったルートをシェアできる機能があって独特なサービスです。Flattest Routeはなんか動かない。とはいえ、今回の題材はコンセプトとしては意外と悪くなかったかなと思います。</description></item><item><title>外部モニターで動画を見ると辛い</title><link>https://raahii.github.io/2016/06/23/euro2016-result-prediction/</link><pubDate>Thu, 23 Jun 2016 17:28:00 +0900</pubDate><guid>https://raahii.github.io/2016/06/23/euro2016-result-prediction/</guid><description>こんにちは。EURO2016盛り上がってますね。みなさん見ていますか。明後日からはトーナメントが始まりますが僕の予想はコレです。
フランス優勝とイタリアが勝ち上がるとこがミソです。山が違っていたら決勝はイタリアvsフランスにしてました。まぁぼく欧州サッカー全然知りませんけど笑
という感じで、最近はEURO2016の試合ハイライトをよく見るのですが、動画鑑賞においてはMacbook Airが思ったより非力で辛いです。
特に、外部モニタで視聴すると、うなる。
ちなみに自分のMBAは2013年モデルの11インチで、cpuはi7の方なのですが、普通にMacのモニタで見ている分には特にcpu（ファン）は暴走しません。反対に、外部接続しているモニタは23インチで、これで見ているとcpuファンがかなり回り始めます。でかいモニタを使うとやはりレンダリングとかの関係で重いんですかね？
ということで、ちょっと気になったので簡単に可視化してみました。
方法はMacモニタと外部モニタでそれぞれ動画を最大化して視聴し、cpu使用率を計測します。ちなみにGoogle Chromeでニコニコ動画を見ました🍺。シンプル。
一応少し頑張ってスクリプトを…。cpu使用率を取得するのはshellscriptで、グラフ化はpythonでやりました。
んで結果、Macモニタの場合 外部モニタの場合
という感じでした。グラフの背景が白で汚い…。
とりあえず、外部モニタの場合，Macのモニタに比べて30%近くcpu使用率が高いという結果に。今回はMacを起動した後に、GoogleChromeだけを立ち上げて動画を視聴という流れで揃えたので、これでもcpu使用率は差が出てない方だと思います。普段からなんとなーくアクティビティモニタを開いて見たりしていますが、他のタブや他のアプリケーションを同時に開いていると、二倍近く差が出る時もあった気がします。やっぱりcpuが非力だと外部モニタって負荷でかいんですね…。
あと、MacはIntelのcpuを積んでいるので、いい感じにオーバークロックして処理性能を上げる「Turbo Boost」という機能がついているみたい。ただ、排熱効率に優れないMacの場合これが原因でcpu温度がみるみる上昇していきます。cpu負荷が大きいプロセスを実行すると、このおせっかい機能によって熱暴走がおきてcpuファンの回転に拍車をかける─ これも原因の一つかなぁ。まぁそんな感じです。
あと今回書いたスクリプトの方は、シェルスクリプトでpsコマンドの出力をcutできなくてちょっと躓きました。結局awkで解決したので、もっとawkを使いこなしたい。あと、シェルスクリプトはスペースが入る文字列を扱うときにわけわからなくなったりするので&#34;と&#39;の違いとかをちゃんと覚えないとダメかも。日頃からもっと頻繁に書いていきたいです。
Pythonの方は去年一年間使ったのでわりとスラスラ書けた。最近はC/C++ばっかり使っているのであれだけど、やっぱりメソッドチェーンは慣れないと読みづらい気がする。matplotlibはとても使いやすいので好き。
grep,sed,awk
作者: 美吉明浩 出版社/メーカー: 秀和システム 発売日: 1998/05/29 メディア: 単行本 この商品を含むブログを見る
コレ読みたい。それでは。</description></item><item><title>Macならできること　ぱーと１</title><link>https://raahii.github.io/2016/06/05/say-command-read-article-for-you/</link><pubDate>Sun, 05 Jun 2016 23:42:00 +0900</pubDate><guid>https://raahii.github.io/2016/06/05/say-command-read-article-for-you/</guid><description>飯を食いながら記事が読みたい．でもご飯を口に入れながら上目遣いでディスプレイを見たり，片手にスマホを持ちながらみたいなのは嫌だという方．
まず，必要に応じてイヤホンをしましょう． 読みたい記事のテキストを選択しクリップボードにコピーしましょう． ターミナルでpbpaste | sayとタイプしましょう． 以上です．高品質な音声合成技術に感謝しましょう． [補足]
読み上げ時の声質を変更したい方はそういったことも可能です． ちょっと打つのがめんどくさいなという人はecho &#39;alias yomiage=&#34;pbpaste | say&#34;&#39; &amp;gt;&amp;gt; ~/.zshrcなどしましょう． そうMacなら，ね．</description></item><item><title>Wordで上下の余白が消えてしまった時</title><link>https://raahii.github.io/2016/05/30/word-margins-disappear-bug/</link><pubDate>Mon, 30 May 2016 10:25:00 +0900</pubDate><guid>https://raahii.github.io/2016/05/30/word-margins-disappear-bug/</guid><description>昨日Word (2016 for Mac)を開いたら画像のように余白が消えて見えなくなってしまっている。 一応余白自体は存在しているらしいが上にスクロールできず、切れてしまっている模様。
解決策はギリギリ見えている余白のところをダブルクリック（これだけ）！
一応ググると下記の記事がヒットする。ここではWordの設定を変更しているみたいだが、Word 2016 for Macにはないので注意。
Wordの上下の余白が消えてしまった場合の対処方法
これ何かの便利機能なのだとしたら意図的にそうする方法を知りたかったり。またWordのおせっかい機能だとしたら激おこ😡ですな。</description></item><item><title>MBA購入と感じたこと</title><link>https://raahii.github.io/2016/04/28/review-macbook-air/</link><pubDate>Thu, 28 Apr 2016 01:25:00 +0900</pubDate><guid>https://raahii.github.io/2016/04/28/review-macbook-air/</guid><description>スペック 前回エントリでは若干Macの購入を渋っていたものの、某フリマで格安で落ちていたため4月頭に購入。スペックは以下の通り。
MacBook Air 2013 cpu i7 memory 8GB SSD 128GB JISキーボード 充放電回数75回 これが¥63000。バカ安い。しかしなぜこんなに格安だったかというと、
充電器が付属していないこと 本体が若干歪んで（曲がって）いること 「かな」キーが半分沈んでいること などが原因のよう。ただ、どれもあまり目立たない上、動作に影響はないようなので個人的には満足度の高い買い物になりました。ただ、フリマでパソコンを購入するという行為はほとんど賭けみたいなもので、あまりおすすめはできません（笑）。
所感 2週間ほど使いました。個人的な話も多いですが…。
良い所 1.08kgめちゃ軽い。荷物重い日でも持ち運びに全く抵抗無し、最高。 学生御用達、デファクトスタンダードのOfficeが動く。ついに！ UNIX。 タッチパッドが広く、ジェスチャが豊富。便利。 キーボードが（打鍵感的な意味で）打ちやすい。 Retinaじゃなくてもやっぱり画面が綺麗。 悪い所 LAN、モニタの入力端子がない。
ThunderboltからVGA、USBからLANの変換ケーブルをそれぞれ購入することで対処。
キーボード配列がちょっと変わってる。
Hey CapsLock, why are you there?
あとは、今までCtrlだけで出来ていた操作をcontrolとcommandで使い分けなければならないのが辛い。今のところ、個人的には統一していただいても全く差し支えないです。あと、commandキーは親指で押すのかな…？　command、control兄弟にメリットを感じる日が来るのを期待。今はとにかく慣れるしかない。
メモリ食い過ぎ。
GoogleChromeが諸悪の根源ではあるものの、やはりUbuntuなどに比べると多い。起動時点で2GBくらい食っててchrome+iTerm+officeとかすると5GB食ってるなんてザラ。オイまだプログラム動かしてないぞ。
とはいいつつも重い処理はAirでは求めてないので、まぁSafari移行などで対処したい。本当にメイン機（？）としてMacを使う場合は16GB積んどくといいかもしれないという学びでもありました。
ウィンドウ操作が貧弱。</description></item><item><title>リーダブル・コード(1)</title><link>https://raahii.github.io/2016/03/04/review-readable-code/</link><pubDate>Fri, 04 Mar 2016 13:54:00 +0900</pubDate><guid>https://raahii.github.io/2016/03/04/review-readable-code/</guid><description>私は現在，人に自分のコードを見てもらう機会はそう多くありません．しかし，今年度は卒業研究を行ったため，作ったプログラムを研究室に残す必要があり，どうせ残すなら読みやすいコードにしたいな，と思い本書を手に取りました．
リーダブルコード ―より良いコードを書くためのシンプルで実践的なテクニック (Theory in practice)
作者: Dustin Boswell,Trevor Foucher,須藤功平,角征典 出版社/メーカー: オライリージャパン 発売日: 2012/06/23 メディア: 単行本（ソフトカバー） 購入: 68人 クリック: 1,802回 この商品を含むブログ (133件) を見る まず，私自身がもともとプログラミングする上でなんとなく意識していたことは次のようなことです．
変数名はより短くするよりも，より客観的に意味が通るものにすべき 変数や関数の命名法は統一すべき 処理は巧妙に短く書くのではなく，多少長くてもストレートに書くべき コメントは書いたほうが良い この内，日頃最も難しいと感じていた部分はやはり変数名です．客観的に意味の通るちょうどよい名前というのはそう簡単に思いつくものではなく，大体省略形にしたり，特に意味のない単語を割り当てたりしていました．
この記事では，「リーダブルコード」を読んで，特に自分が実践したいと思ったことについてまとめていきます．また，今回は「リーダブル・コード」の第一部のみをピックアップし，基本的には「表面的な部分を変更する」ことでよりコードをリーダブルにする方法をまとめたものです．
1. 命名はより的確な単語を使う それが思いつかないから困ってるという話なわけですが，ここで言いたいことは，すぐに思いつく「汎用的な単語」を安易に選択せず，より「限定的なニュアンスの単語」を選択するべきだということです．
例えば，
#インターネットからページ情報を取得する def GetPage(url): のような関数ならば，GetではなくFetchやDownloadを使うとわかりやすくなります．「取得する」んだからとりあえず…と汎用的な単語であるgetを使うと意味がぼやけるのです．他にも，
#textの最後を切り落として「．．．」をつける def Clip(text, length): のような関数では，よくあるlengthを引数として使ってしまいがちですが，長さ(length)の単位によってもっと具体的に
単位 引数 行数 row 文字数 char 単語数 word バイト数 byte などを使い分けるのが適切です．このように，より限定的な意味の単語を選択することで読み手の誤解を減らし，わかりやすくすることができます．自分は他にもmakeやconvertを多用する傾向にあるので気をつけたいです．</description></item><item><title>人工知能とは</title><link>https://raahii.github.io/2015/11/14/artificial-intelligent/</link><pubDate>Sat, 14 Nov 2015 17:47:00 +0900</pubDate><guid>https://raahii.github.io/2015/11/14/artificial-intelligent/</guid><description>動機付け
最近、機械学習やディープラーンニングといった手法で人工知能研究が話題を集めている。特に今年学校で卒業研究が始まり、音声信号処理っぽいことをしているのだが、音声認識とか音声合成、声質変換あたりのこと調べると、すぐに統計的な手法に出会う。 例えば音声認識では、与えられた音声に対してそれが「あいうえお」のどの母音であるかをフォルマントという特徴量で判断したりするが、これを行うためには、あらかじめたくさんデータを用意して、第一フォルマントと第二フォルマントという特徴量の分布で、ここからここまでが「あ」ですよ、ここからは「い」ですよ、みたいな線引きをしてやらなければいけない。これはクラスタリング？という機械学習のアルゴリズムの一つだ。
はっきり言って、詳しいことは自分もわからないが、とにかくざっくりと「人工知能ってなんだ？」という質問にイメージをつけるべく、そのアウトラインをまとめようとこの文章を書いた。というのも、つい先日、「人工知能とか機械学習ってなんなの？」と聞かれ、「なんだろうね？笑」となってしまったのがきっかけである。
「人工知能は人間を超えるか」をざっくり　
人工知能は人間を超えるか ディープラーニングの先にあるもの (角川EPUB選書)
作者: 松尾豊 出版社/メーカー: KADOKAWA/中経出版 発売日: 2015/03/11 メディア: 単行本 この商品を含むブログ (8件) を見る 人工知能研究について 　そもそも、人工知能の定義とはなんだろう。これは専門家によってさまざまだが、一口に言えば「究極には人間と区別がつかない人工的な知能のこと」である。その人工知能を実現するために、さまざまな手法が考えられてきたわけだが、人工知能研究には現在までに3つのブームが存在したそうだ。これら3つこそが、人工知能をどのような手法で実現しようとしたのかを示す大きなまとまりになっている。これらを簡単にまとめることで、なんとなく機械学習やディープラーンニングが流行っている理由がわかるんじゃなかろうか。
第一のブーム 　1955~1970年頃のこと。その中身は主に推論と探索である。これは、いたってシンプルなルール によって現実の問題を解こうとするものである。
　ではいったいどんな問題を解いたのかというと、一つは迷路。これはスタート地点から考えられるすべての経路（場合分け）を順に調べることによってゴールを見つけるものである。主に探索木をモデルに用いていて、「深さ優先探索」や「幅優先探索」といったアルゴリズムが存在する。これらはわりと耳なじみがあると思う。他にも、ハノイの塔なども簡単に解ける。ハノイの塔にはちゃんとルールがあるので、それを満たすようにただシンプルな操作を繰り返すだけだ。
　一方、電脳戦で有名な将棋などのボードゲームに関しても、基本的に推論や探索で解く。しかしこの場合、「相手」がいることによって組み合わせが膨大になるため、すべての場合を列挙することは不可能だ。そのため、その時その時の盤面の状況に対して考えられる次の一手をすべて洗い出し、なんらかの評価手法でスコアをつけることによって最善に最善に手を打っていくことになる。これに関しては、盤面の評価に使用する特徴量(例えば飛車や角があるかないか、王がどこにいるか、など)が研究が進むにつれて良いものになっていったり、第3のブームで登場する機械学習を利用することによって現在も進化し続けているのだが、基本は推論、探索である。
　とにかく、単純な操作を多く繰り返す処理なら、パソコン用いた方が我々より早く正確であることは自明で、それを用いて賢く見せているにすぎない と言える(パソコン、インターネットが普及した今ではなんだか当たり前だけど)。お分かりのように、この推論や探索といった手法単体では、明確に定義されたルールの中で最適な解を求めることしかできず、いわゆるトイプロブレムは解けても、現実の複雑な問題を解くことはできない 。このような形で第一のブームは幕を閉じる。
第二のブーム 　1982~2000年くらいまで。その中身は機械に実践的な知識を持たせることである。第一のブームではシンプルな操作を繰り返すことがメインだったが、今度は必要な知識を機械に持たせることによってエキスパートシステムを作ろうと試みたのである。
　実際に開発されたエキスパートシステムには、1970年にスタンフォード大学でつくられたMYCINなどが挙げられる。MYCINは伝染病の血液疾患の患者を診断し、抗生物質を処方する、いわば専門医の代わりとなるシステムである。あらかじめ用意した500のルールに従って患者に質問を行い、条件分岐して患者が感染した細菌を特定し、適切な抗生物質を処方する。他にも、比較的最近話題となった、自分が思い浮かべたアニメキャラや有名人などを言い当てる「アキネイター」もこの種のシステムだろう。
　このようなエキスパートシステムを作るのには、知識を集めるためのコストがかかること、そして、知識が増えれば増えるほど、条件分岐が複雑かつ膨大になり、矛盾も発生するといった問題がついて回る。しかし、コンピュータの性能が日進月歩である今、それらは大した問題ではない。それよりも、次に上げる二つの致命的な問題がある。
　一つは、人間にとって常識レベルの知識が途方もなく膨大であるということである。例えば、機械翻訳をする時、&#34;He saw a woman in the garden with a telescope.&#34;という文章を日本語に訳そうとすると、in the gardenとwith a telescopeの節がHeにかかるのかwomanにかかるのか一意に定まらない。しかし、人間であれば常識的に「彼は望遠鏡で庭にいる女性を見た。」と訳すことができる。このように、エキスパートシステムを拡張させ、より柔軟なものにしようとした時、そこには「常識的な判断」というものが必要不可欠になるが、それが非常に難しかったのである。</description></item><item><title>Pythonの日本語文字列</title><link>https://raahii.github.io/2015/06/28/nlp-100-knock/</link><pubDate>Sun, 28 Jun 2015 21:10:00 +0900</pubDate><guid>https://raahii.github.io/2015/06/28/nlp-100-knock/</guid><description>「研究者流コーディングの極意」を読んで、なんだかためになりそうだし、面白そうだし、ということで言語処理100本ノックを始めてみました。そして2つ目で詰まった(早い)。
使っている言語はPythonで、使い始めたばかりなのですが、そもそもプログラミングがダメダメです。
まず、その問題ですが、
&amp;lt;blockquote&amp;gt; &amp;lt;p&amp;gt;01. 「パタトクカシーー」&amp;lt;br&amp;gt; 「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．
&amp;lt;/blockquote&amp;gt; です。
まず私が考えたのは、こんな感じです。なんの疑問もなくこれでいけるだろうと思ってました笑。
string=&amp;ldquo;パタトクカシーー&amp;rdquo; rev=&amp;ldquo;&amp;rdquo; for i in [1,3,5,7]: rev+=string[i] print rev
一方結果は、
% python 01.「パタトクカシーー」.py �㿃 なんか文字化けしてる…。
それもそのはずで、「パタトクカシーー」は全て全角文字なのでひとひねり必要です。一般に半角は1byte、全角は2byteに符号化されているので、配列のお部屋と1:1対応にならないのが原因。
そしてPythonの場合、通常のstr型の全角文字は3byteに符号化されている（お部屋3つに対応している）みたいです。
&amp;gt;&amp;gt;&amp;gt; &amp;lsquo;あ&amp;rsquo;[0] &amp;lsquo;\xe3&amp;rsquo; &amp;gt;&amp;gt;&amp;gt; &amp;lsquo;あ&amp;rsquo;[1] &amp;lsquo;\x81&amp;rsquo; &amp;gt;&amp;gt;&amp;gt; &amp;lsquo;あ&amp;rsquo;[2] &amp;lsquo;\x82&amp;rsquo; &amp;gt;&amp;gt;&amp;gt; &amp;lsquo;あ&amp;rsquo;[3] Traceback (most recent call last): File &amp;ldquo;&amp;lt;stdin&amp;gt;&amp;rdquo;, line 1, in &amp;lt;module&amp;gt; IndexError: string index out of range この記事が参考になりました。qiita.com
これを知ったうえで愚直に書き換えると、
string=&amp;ldquo;パタトクカシーー&amp;rdquo; rev=&amp;ldquo;&amp;rdquo; for i in [1,3,5,7]: for j in range(3):#全角なので rev+=string[3*i+j] print rev</description></item><item><title>AboutMe</title><link>https://raahii.github.io/aboutme/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://raahii.github.io/aboutme/</guid><description>About Me Name: Yuki Nakahira
Master&amp;rsquo;s student, Science and Engineering at University of Chiba
Mail: piyo56.net@gmail.com
Links:
Github Twitter Labo Interest:
Web backend (golang) Computer Vision (GAN) Football ⚽ Fashion 👖 Recent coding status:
Work App, Web service ・ShowTime (2019 / 08, M2)
&amp;ldquo;あなたのプレゼンをもっと面白く&amp;rdquo;
ShowTimeはプレゼンの際に発表者のポーズに応じてスライドを進めたり，効果音を鳴らすことで，発表にメリハリと笑いを与えてくれるツールです． HackU2019にて制作．発表者のポーズ認識（機械学習）の実装，及びサーバーサイドを担当．
Links: Github, Hack U 2019 TOKYO Student Hackathon - Yahoo! JAPAN</description></item></channel></rss>